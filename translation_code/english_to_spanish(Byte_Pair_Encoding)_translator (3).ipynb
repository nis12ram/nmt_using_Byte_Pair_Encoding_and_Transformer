{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qe4n0y_He3Km"
      },
      "outputs": [],
      "source": [
        "from byte_pair_level_transformer import Transformer\n",
        "import torch\n",
        "import numpy as np\n",
        "import re\n",
        "import collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1pBj3ma7hVc4"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/spa.txt'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ge2rvFA0yZuR"
      },
      "outputs": [],
      "source": [
        "def text_preprocessing(text):\n",
        "  # text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n",
        "  text = re.sub(r'[\" \"]+', \" \", text)\n",
        "  # text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text)\n",
        "  text = re.sub(r\"[^a-zA-Z]+\", \" \", text)\n",
        "\n",
        "  text = text.strip().lower()\n",
        "\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ViD2B7hgyuKx"
      },
      "outputs": [],
      "source": [
        "num_data = 70000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8zWU4rSJik85"
      },
      "outputs": [],
      "source": [
        "with open(file_path,'r') as f:\n",
        "  lines = f.readlines()\n",
        "english_sentence,spanish_sentence = [],[]\n",
        "for total_example,line in enumerate(lines):\n",
        "  if (total_example < num_data ):\n",
        "    line = line.lower()\n",
        "    data = line.replace(\"\\n\",\"\").split(\"\\t\")\n",
        "    data[0] = text_preprocessing(data[0])\n",
        "    data[1] = text_preprocessing(data[1])\n",
        "    english_sentence.append(data[0])\n",
        "    spanish_sentence.append(data[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "S6x1jFuOR7tn"
      },
      "outputs": [],
      "source": [
        "spanish_vocabulary = []\n",
        "english_vocabulary = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t_3PTj5uLsiw"
      },
      "outputs": [],
      "source": [
        "for en,sp in zip(english_sentence,spanish_sentence):\n",
        "  en_tokens = en.split()\n",
        "  sp_tokens = sp.split()\n",
        "  for en_token,sp_token in zip(en_tokens,sp_tokens):\n",
        "    if en_token not in english_vocabulary:\n",
        "      english_vocabulary.append(en_token)\n",
        "    if sp_token not in spanish_vocabulary:\n",
        "      spanish_vocabulary.append(sp_token)\n",
        "  # print(english_vocabulary)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IL54ucE73i13"
      },
      "outputs": [],
      "source": [
        "# vocab_limit = 9000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IkLWejZ3bcXn"
      },
      "outputs": [],
      "source": [
        "# english_vocabulary = english_vocabulary[:vocab_limit]\n",
        "\n",
        "# spanish_vocabulary = spanish_vocabulary[:vocab_limit]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hLMxoXfchi6W"
      },
      "outputs": [],
      "source": [
        "# index_to_spanish = {index:word for index,word in enumerate(spanish_vocabulary)}\n",
        "# spanish_to_index = {word:index for index,word in enumerate(spanish_vocabulary)}\n",
        "# index_to_english = {index:word for index,word in enumerate(english_vocabulary)}\n",
        "# english_to_index = {word:index for index,word in enumerate(english_vocabulary)}\n",
        "# # print(spanish_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8Dv2I1FOKub",
        "outputId": "ca795012-744d-4673-ba8a-290af9ecc594"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7985, 14068)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(english_vocabulary),len(spanish_vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "a8BnIXcSngHJ"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "en_word_freq_dict  = collections.defaultdict(int)\n",
        "\n",
        "for word in english_vocabulary:\n",
        "  en_word_freq_dict[\" \".join(word) + ' #'] += 1\n",
        "# en_word_freq_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qr0fiCGbn7OQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "sp_word_freq_dict  = collections.defaultdict(int)\n",
        "\n",
        "for word in spanish_vocabulary:\n",
        "  sp_word_freq_dict[\" \".join(word) + ' #'] += 1\n",
        "# sp_word_freq_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "t8xezAN3nDI-"
      },
      "outputs": [],
      "source": [
        "def get_pairs(word_freq_dict):\n",
        "  '''\n",
        "  goal:\n",
        "      used to get the pairs dict:\n",
        "                key(tuple{str,str}): represent the byte pairs\n",
        "                values(int): represent the frequency of the byte pair\n",
        "      and return the pairs dict\n",
        "  '''\n",
        "  pairs = collections.defaultdict(int)\n",
        "  for word, freq in word_freq_dict.items():\n",
        "    chars = word.split()\n",
        "    for i in range(len(chars)-1):\n",
        "      pairs[chars[i],chars[i+1]] += freq\n",
        "  return pairs\n",
        "\n",
        "def merge_byte_pairs(best_pair, word_freq_dict):\n",
        "  '''\n",
        "  goal:\n",
        "      used to merge the byte pairs that has highest frequency\n",
        "      and return the merged dict{new word_freq_dict}\n",
        "  '''\n",
        "  # print(best_pair)\n",
        "  merged_dict = {}\n",
        "  bigram = re.escape(' '.join(best_pair))\n",
        "  # print(f'bigram {bigram}')\n",
        "  p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
        "  # print(f'p {p}')\n",
        "  for word in word_freq_dict:\n",
        "    # print(word)\n",
        "    w_out = p.sub(''.join(best_pair), word) # merging best byte pair.\n",
        "    # print(f'w_out {w_out}')\n",
        "    merged_dict[w_out] = word_freq_dict[word]\n",
        "  return merged_dict\n",
        "\n",
        "def get_subword_tokens(word_freq_dict):\n",
        "  char_freq_dict = collections.defaultdict(int)\n",
        "  for word,freq in word_freq_dict.items():\n",
        "    chars = word.split()\n",
        "    for char in chars:\n",
        "      char_freq_dict[char] += freq\n",
        "  return char_freq_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iZa_uxwdojLB"
      },
      "outputs": [],
      "source": [
        "for i in range(9000):\n",
        "  # if (i == 0):\n",
        "    # print(f'{get_subword_tokens(en_word_freq_dict)}')\n",
        "    # print('')\n",
        "  pairs = get_pairs(en_word_freq_dict)\n",
        "  try:\n",
        "    best_pair = max(pairs,key = pairs.get)\n",
        "  except:\n",
        "    break\n",
        "  # print(f\"Iteration {i}: \")\n",
        "  en_word_freq_dict = merge_byte_pairs(best_pair,en_word_freq_dict)\n",
        "  en_subword_tokens = get_subword_tokens(en_word_freq_dict)\n",
        "  # print(en_subword_tokens)\n",
        "  # print(len(en_subword_tokens))\n",
        "  # print()\n",
        "  i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Zf1X-CK3o2iY"
      },
      "outputs": [],
      "source": [
        "\n",
        "for i in range(9000):\n",
        "  # if (i == 0):\n",
        "  #   print(f'{get_subword_tokens(sp_word_freq_dict)}')\n",
        "  #   print('')\n",
        "  pairs = get_pairs(sp_word_freq_dict)\n",
        "  try:\n",
        "    best_pair = max(pairs,key = pairs.get)\n",
        "  except:\n",
        "    break\n",
        "  # print(f\"Iteration {i}: \")\n",
        "  sp_word_freq_dict = merge_byte_pairs(best_pair,sp_word_freq_dict)\n",
        "  sp_subword_tokens = get_subword_tokens(sp_word_freq_dict)\n",
        "  # print(sp_subword_tokens)\n",
        "  # print(len(sp_subword_tokens))\n",
        "  # print()\n",
        "  i += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_token_length(token):\n",
        "    if token[-4:] == '#':\n",
        "        return len(token[:-4]) + 1\n",
        "    else:\n",
        "        return len(token)"
      ],
      "metadata": {
        "id": "pnqg1ws4dQsK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Byte pair vocabulary"
      ],
      "metadata": {
        "id": "IPn88g2Nkhg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_sorted_tokens_tuple = sorted(en_subword_tokens.items(), key=lambda item: (measure_token_length(item[0]), item[1]), reverse=True)\n",
        "sp_sorted_tokens_tuple = sorted(sp_subword_tokens.items(), key=lambda item: (measure_token_length(item[0]), item[1]), reverse=True)\n"
      ],
      "metadata": {
        "id": "elC0oO-qdGSq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_sorted_tokens_tuple[0],en_sorted_tokens_tuple[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-XffxrmeeHr",
        "outputId": "5a2b64fd-703e-486c-c8f7-6d393614d62a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('hyperventilating#', 1), ('q', 1))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_vocab_tokenization = [token for (token, freq) in en_sorted_tokens_tuple]\n",
        "sp_vocab_tokenization = [token for (token, freq) in sp_sorted_tokens_tuple]"
      ],
      "metadata": {
        "id": "0bp_g3MF5iL2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(en_vocab_tokenization),len(sp_vocab_tokenization)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73vakBe85kjb",
        "outputId": "df2f7cab-cd5a-4d34-e9c1-32949e8f986d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7322, 8354)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_vocab_tokenization[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJKXNramfnv3",
        "outputId": "4c08df31-1422-4e57-94ba-9de20d717f9f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hyperventilating#',\n",
              " 'congratulations#',\n",
              " 'understandable#',\n",
              " 'claustrophobic#',\n",
              " 'underestimated#',\n",
              " 'disappointment#',\n",
              " 'discrimination#',\n",
              " 'concentrating#',\n",
              " 'misunderstood#',\n",
              " 'flabbergasted#']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_lng_to_index = {}\n",
        "en_index_to_lng = {}\n",
        "k = 4\n",
        "for i in en_vocab_tokenization:\n",
        "  en_lng_to_index[i] = k\n",
        "  en_index_to_lng[k] = i\n",
        "  k += 1\n",
        "\n",
        "\n",
        "sp_lng_to_index = {}\n",
        "sp_index_to_lng = {}\n",
        "k = 4\n",
        "for i in sp_vocab_tokenization:\n",
        "  sp_lng_to_index[i] = k\n",
        "  sp_index_to_lng[k] = i\n",
        "  k += 1"
      ],
      "metadata": {
        "id": "1irLJNPW5m7a"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "START_TOKEN = '<START>'\n",
        "PADDING_TOKEN = '<PAD>'\n",
        "END_TOKEN = '<END>'\n",
        "\n",
        "en_index_to_lng[0] = '<OOV>'\n",
        "sp_index_to_lng[0] = '<OOV>'\n",
        "en_index_to_lng[1] = '<START>'\n",
        "sp_index_to_lng[1] = '<START>'\n",
        "en_index_to_lng[2] = '<END>'\n",
        "sp_index_to_lng[2] = '<END>'\n",
        "en_index_to_lng[3] = '<PAD>'\n",
        "sp_index_to_lng[3] = '<PAD>'\n",
        "\n",
        "en_lng_to_index['<OOV>'] = 0\n",
        "sp_lng_to_index['<OOV>'] = 0\n",
        "en_lng_to_index['<START>'] = 1\n",
        "sp_lng_to_index['<START>'] = 1\n",
        "en_lng_to_index['<END>'] = 2\n",
        "sp_lng_to_index['<END>'] = 2\n",
        "en_lng_to_index['<PAD>'] = 3\n",
        "sp_lng_to_index['<PAD>'] = 3"
      ],
      "metadata": {
        "id": "-T2GFwgc2cuV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_lng_to_index,sp_lng_to_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhO0WBLX5pXF",
        "outputId": "b2f16798-1dc8-4e97-eacd-a07d36278818"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'hyperventilating#': 4,\n",
              "  'congratulations#': 5,\n",
              "  'understandable#': 6,\n",
              "  'claustrophobic#': 7,\n",
              "  'underestimated#': 8,\n",
              "  'disappointment#': 9,\n",
              "  'discrimination#': 10,\n",
              "  'concentrating#': 11,\n",
              "  'misunderstood#': 12,\n",
              "  'flabbergasted#': 13,\n",
              "  'cardiologists#': 14,\n",
              "  'consciousness#': 15,\n",
              "  'archaeologist#': 16,\n",
              "  'disappointing#': 17,\n",
              "  'pseudoscience#': 18,\n",
              "  'overemotional#': 19,\n",
              "  'uncomfortable#': 20,\n",
              "  'extraordinary#': 21,\n",
              "  'inappropriate#': 22,\n",
              "  'disillusioned#': 23,\n",
              "  'inconsiderate#': 24,\n",
              "  'misunderstand#': 25,\n",
              "  'underestimate#': 26,\n",
              "  'indispensable#': 27,\n",
              "  'individualist#': 28,\n",
              "  'congratulated#': 29,\n",
              "  'hypochondriac#': 30,\n",
              "  'investigating#': 31,\n",
              "  'butterfingers#': 32,\n",
              "  'eavesdropping#': 33,\n",
              "  'encouragingly#': 34,\n",
              "  'understanding#': 35,\n",
              "  'experimenting#': 36,\n",
              "  'unbelievable#': 37,\n",
              "  'embarrassing#': 38,\n",
              "  'melodramatic#': 39,\n",
              "  'homeschooled#': 40,\n",
              "  'housesitting#': 41,\n",
              "  'overreacting#': 42,\n",
              "  'thanksgiving#': 43,\n",
              "  'honeymooning#': 44,\n",
              "  'disappointed#': 45,\n",
              "  'unacceptable#': 46,\n",
              "  'complimented#': 47,\n",
              "  'ambidextrous#': 48,\n",
              "  'conservative#': 49,\n",
              "  'disagreeable#': 50,\n",
              "  'hypocritical#': 51,\n",
              "  'incorrigible#': 52,\n",
              "  'intellectual#': 53,\n",
              "  'irresistible#': 54,\n",
              "  'unscrupulous#': 55,\n",
              "  'exterminator#': 56,\n",
              "  'unattractive#': 57,\n",
              "  'carcinogenic#': 58,\n",
              "  'exhilarating#': 59,\n",
              "  'appendicitis#': 60,\n",
              "  'electrocuted#': 61,\n",
              "  'hospitalized#': 62,\n",
              "  'unsuccessful#': 63,\n",
              "  'unemployment#': 64,\n",
              "  'bullfighting#': 65,\n",
              "  'overestimate#': 66,\n",
              "  'discouraging#': 67,\n",
              "  'unforgivable#': 68,\n",
              "  'marshmallows#': 69,\n",
              "  'cardiologist#': 70,\n",
              "  'photographer#': 71,\n",
              "  'quadriplegic#': 72,\n",
              "  'birdwatching#': 73,\n",
              "  'instructions#': 74,\n",
              "  'conventional#': 75,\n",
              "  'architecture#': 76,\n",
              "  'relationship#': 77,\n",
              "  'interrupting#': 78,\n",
              "  'interjection#': 79,\n",
              "  'kindergarten#': 80,\n",
              "  'blackmailing#': 81,\n",
              "  'uninterested#': 82,\n",
              "  'organization#': 83,\n",
              "  'manipulating#': 84,\n",
              "  'breathlessly#': 85,\n",
              "  'alternatives#': 86,\n",
              "  'responsible#': 87,\n",
              "  'disciplined#': 88,\n",
              "  'contributed#': 89,\n",
              "  'exaggerated#': 90,\n",
              "  'rescheduled#': 91,\n",
              "  'volunteered#': 92,\n",
              "  'accelerated#': 93,\n",
              "  'surrendered#': 94,\n",
              "  'humiliating#': 95,\n",
              "  'interesting#': 96,\n",
              "  'unfortunate#': 97,\n",
              "  'disappeared#': 98,\n",
              "  'exaggerates#': 99,\n",
              "  'understands#': 100,\n",
              "  'immediately#': 101,\n",
              "  'concentrate#': 102,\n",
              "  'intelligent#': 103,\n",
              "  'dumbfounded#': 104,\n",
              "  'complaining#': 105,\n",
              "  'apologizing#': 106,\n",
              "  'interfering#': 107,\n",
              "  'precautions#': 108,\n",
              "  'blackmailed#': 109,\n",
              "  'influential#': 110,\n",
              "  'introverted#': 111,\n",
              "  'fashionable#': 112,\n",
              "  'hyperactive#': 113,\n",
              "  'unconscious#': 114,\n",
              "  'embarrassed#': 115,\n",
              "  'unstoppable#': 116,\n",
              "  'workaholics#': 117,\n",
              "  'heartbroken#': 118,\n",
              "  'information#': 119,\n",
              "  'candlelight#': 120,\n",
              "  'butterflies#': 121,\n",
              "  'handcrafted#': 122,\n",
              "  'distraction#': 123,\n",
              "  'fascinating#': 124,\n",
              "  'outstanding#': 125,\n",
              "  'unimportant#': 126,\n",
              "  'unnecessary#': 127,\n",
              "  'adventurous#': 128,\n",
              "  'incompetent#': 129,\n",
              "  'independent#': 130,\n",
              "  'insensitive#': 131,\n",
              "  'intoxicated#': 132,\n",
              "  'mischievous#': 133,\n",
              "  'patronizing#': 134,\n",
              "  'pessimistic#': 135,\n",
              "  'charismatic#': 136,\n",
              "  'cooperating#': 137,\n",
              "  'defenseless#': 138,\n",
              "  'egotistical#': 139,\n",
              "  'comfortable#': 140,\n",
              "  'mathematics#': 141,\n",
              "  'complicated#': 142,\n",
              "  'appointment#': 143,\n",
              "  'convulsions#': 144,\n",
              "  'criticizing#': 145,\n",
              "  'intolerable#': 146,\n",
              "  'tonsillitis#': 147,\n",
              "  'blindfolded#': 148,\n",
              "  'outnumbered#': 149,\n",
              "  'stomachache#': 150,\n",
              "  'temperature#': 151,\n",
              "  'inseparable#': 152,\n",
              "  'neurologist#': 153,\n",
              "  'overpowered#': 154,\n",
              "  'recommended#': 155,\n",
              "  'reluctantly#': 156,\n",
              "  'imagination#': 157,\n",
              "  'resourceful#': 158,\n",
              "  'afghanistan#': 159,\n",
              "  'pickpockets#': 160,\n",
              "  'interpreted#': 161,\n",
              "  'beautifully#': 162,\n",
              "  'anticipated#': 163,\n",
              "  'inspiration#': 164,\n",
              "  'interpreter#': 165,\n",
              "  'explanation#': 166,\n",
              "  'grandfather#': 167,\n",
              "  'appreciates#': 168,\n",
              "  'shorthanded#': 169,\n",
              "  'catastrophe#': 170,\n",
              "  'reservation#': 171,\n",
              "  'approaching#': 172,\n",
              "  'bookkeeping#': 173,\n",
              "  'downloading#': 174,\n",
              "  'forgiveness#': 175,\n",
              "  'overreacted#': 176,\n",
              "  'indifferent#': 177,\n",
              "  'handwriting#': 178,\n",
              "  'negotiation#': 179,\n",
              "  'surrounding#': 180,\n",
              "  'grandmother#': 181,\n",
              "  'voluntarily#': 182,\n",
              "  'alternative#': 183,\n",
              "  'approvingly#': 184,\n",
              "  'transplants#': 185,\n",
              "  'differences#': 186,\n",
              "  'congressman#': 187,\n",
              "  'conciseness#': 188,\n",
              "  'incorrectly#': 189,\n",
              "  'proposition#': 190,\n",
              "  'cooperation#': 191,\n",
              "  'agriculture#': 192,\n",
              "  'hardworking#': 193,\n",
              "  'unthinkable#': 194,\n",
              "  'girlfriends#': 195,\n",
              "  'unholstered#': 196,\n",
              "  'attentively#': 197,\n",
              "  'competition#': 198,\n",
              "  'nationality#': 199,\n",
              "  'electricity#': 200,\n",
              "  'convenience#': 201,\n",
              "  'appropriate#': 202,\n",
              "  'considerate#': 203,\n",
              "  'reasonable#': 204,\n",
              "  'apologized#': 205,\n",
              "  'understand#': 206,\n",
              "  'respectful#': 207,\n",
              "  'supportive#': 208,\n",
              "  'everything#': 209,\n",
              "  'disgusting#': 210,\n",
              "  'diplomatic#': 211,\n",
              "  'remodeling#': 212,\n",
              "  'speechless#': 213,\n",
              "  'undressing#': 214,\n",
              "  'unemployed#': 215,\n",
              "  'approached#': 216,\n",
              "  'improvised#': 217,\n",
              "  'intervened#': 218,\n",
              "  'remembered#': 219,\n",
              "  'understood#': 220,\n",
              "  'dinnertime#': 221,\n",
              "  'incredible#': 222,\n",
              "  'misleading#': 223,\n",
              "  'sweltering#': 224,\n",
              "  'practicing#': 225,\n",
              "  'squabbling#': 226,\n",
              "  'whimpering#': 227,\n",
              "  'exaggerate#': 228,\n",
              "  'yourselves#': 229,\n",
              "  'fascinated#': 230,\n",
              "  'distracted#': 231,\n",
              "  'appreciate#': 232,\n",
              "  'outsmarted#': 233,\n",
              "  'astonished#': 234,\n",
              "  'dumbstruck#': 235,\n",
              "  'unreliable#': 236,\n",
              "  'classmates#': 237,\n",
              "  'sophomores#': 238,\n",
              "  'imprisoned#': 239,\n",
              "  'hypocrites#': 240,\n",
              "  'mosquitoes#': 241,\n",
              "  'sandwiches#': 242,\n",
              "  'sauerkraut#': 243,\n",
              "  'watermelon#': 244,\n",
              "  'california#': 245,\n",
              "  'interested#': 246,\n",
              "  'conspiracy#': 247,\n",
              "  'prediction#': 248,\n",
              "  'volunteers#': 249,\n",
              "  'reconsider#': 250,\n",
              "  'aggressive#': 251,\n",
              "  'impossible#': 252,\n",
              "  'irrelevant#': 253,\n",
              "  'ridiculous#': 254,\n",
              "  'terrifying#': 255,\n",
              "  'downstairs#': 256,\n",
              "  'hysterical#': 257,\n",
              "  'indiscreet#': 258,\n",
              "  'intolerant#': 259,\n",
              "  'meditating#': 260,\n",
              "  'mesmerized#': 261,\n",
              "  'optimistic#': 262,\n",
              "  'passionate#': 263,\n",
              "  'stuttering#': 264,\n",
              "  'unfaithful#': 265,\n",
              "  'vulnerable#': 266,\n",
              "  'recognized#': 267,\n",
              "  'threatened#': 268,\n",
              "  'collection#': 269,\n",
              "  'disappoint#': 270,\n",
              "  'surrounded#': 271,\n",
              "  'englishman#': 272,\n",
              "  'aristocrat#': 273,\n",
              "  'stepfather#': 274,\n",
              "  'completely#': 275,\n",
              "  'cigarettes#': 276,\n",
              "  'psychology#': 277,\n",
              "  'television#': 278,\n",
              "  'photogenic#': 279,\n",
              "  'intriguing#': 280,\n",
              "  'brightened#': 281,\n",
              "  'handcuffed#': 282,\n",
              "  'plagiarism#': 283,\n",
              "  'remarkable#': 284,\n",
              "  'surprising#': 285,\n",
              "  'devastated#': 286,\n",
              "  'disfigured#': 287,\n",
              "  'frightened#': 288,\n",
              "  'humiliated#': 289,\n",
              "  'hypnotized#': 290,\n",
              "  'indecisive#': 291,\n",
              "  'ostracized#': 292,\n",
              "  'frustrated#': 293,\n",
              "  'overworked#': 294,\n",
              "  'disturbing#': 295,\n",
              "  'depressing#': 296,\n",
              "  'everywhere#': 297,\n",
              "  'increasing#': 298,\n",
              "  'disconnect#': 299,\n",
              "  'vegetables#': 300,\n",
              "  'experience#': 301,\n",
              "  'adventures#': 302,\n",
              "  'cantaloupe#': 303,\n",
              "  'suspicious#': 304,\n",
              "  'absolutely#': 305,\n",
              "  'incredibly#': 306,\n",
              "  'appetizing#': 307,\n",
              "  'unbearably#': 308,\n",
              "  'infallible#': 309,\n",
              "  'unexpected#': 310,\n",
              "  'christians#': 311,\n",
              "  'professors#': 312,\n",
              "  'challenged#': 313,\n",
              "  'confronted#': 314,\n",
              "  'encouraged#': 315,\n",
              "  'eventually#': 316,\n",
              "  'persecuted#': 317,\n",
              "  'biochemist#': 318,\n",
              "  'politician#': 319,\n",
              "  'psychopath#': 320,\n",
              "  'workaholic#': 321,\n",
              "  'scribbling#': 322,\n",
              "  'questioned#': 323,\n",
              "  'subjective#': 324,\n",
              "  'imitations#': 325,\n",
              "  'contagious#': 326,\n",
              "  'clumsiness#': 327,\n",
              "  'gracefully#': 328,\n",
              "  'girlfriend#': 329,\n",
              "  'portuguese#': 330,\n",
              "  'daydreamed#': 331,\n",
              "  'discussion#': 332,\n",
              "  'kazakhstan#': 333,\n",
              "  'sunglasses#': 334,\n",
              "  'disrespect#': 335,\n",
              "  'lightbulbs#': 336,\n",
              "  'colorblind#': 337,\n",
              "  'motorcycle#': 338,\n",
              "  'nightmares#': 339,\n",
              "  'recognizes#': 340,\n",
              "  'resistance#': 341,\n",
              "  'miniskirts#': 342,\n",
              "  'assistance#': 343,\n",
              "  'dictionary#': 344,\n",
              "  'overflowed#': 345,\n",
              "  'separately#': 346,\n",
              "  'gramophone#': 347,\n",
              "  'foreigners#': 348,\n",
              "  'accountant#': 349,\n",
              "  'evangelist#': 350,\n",
              "  'discipline#': 351,\n",
              "  'motivation#': 352,\n",
              "  'arithmetic#': 353,\n",
              "  'basketball#': 354,\n",
              "  'nonplussed#': 355,\n",
              "  'fertilizer#': 356,\n",
              "  'lumberjack#': 357,\n",
              "  'prohibited#': 358,\n",
              "  'dislocated#': 359,\n",
              "  'harvesting#': 360,\n",
              "  'definitely#': 361,\n",
              "  'afterwards#': 362,\n",
              "  'councillor#': 363,\n",
              "  'goosebumps#': 364,\n",
              "  'stiflingly#': 365,\n",
              "  'investment#': 366,\n",
              "  'childishly#': 367,\n",
              "  'painkiller#': 368,\n",
              "  'comparison#': 369,\n",
              "  'brainchild#': 370,\n",
              "  'conscience#': 371,\n",
              "  'inevitable#': 372,\n",
              "  'difference#': 373,\n",
              "  'discovered#': 374,\n",
              "  'whispering#': 375,\n",
              "  'inflexible#': 376,\n",
              "  'tortellini#': 377,\n",
              "  'newspapers#': 378,\n",
              "  'pronounced#': 379,\n",
              "  'memorizing#': 380,\n",
              "  'personally#': 381,\n",
              "  'medication#': 382,\n",
              "  'overcooked#': 383,\n",
              "  'incentives#': 384,\n",
              "  'monumental#': 385,\n",
              "  'infectious#': 386,\n",
              "  'blackboard#': 387,\n",
              "  'quantities#': 388,\n",
              "  'flattering#': 389,\n",
              "  'automobile#': 390,\n",
              "  'lighthouse#': 391,\n",
              "  'protection#': 392,\n",
              "  'introduced#': 393,\n",
              "  'transplant#': 394,\n",
              "  'microscope#': 395,\n",
              "  'washington#': 396,\n",
              "  'philosophy#': 397,\n",
              "  'toothpaste#': 398,\n",
              "  'disneyland#': 399,\n",
              "  'alcoholism#': 400,\n",
              "  'apparently#': 401,\n",
              "  'attendance#': 402,\n",
              "  'underwater#': 403,\n",
              "  'negotiable#': 404,\n",
              "  'forewarned#': 405,\n",
              "  'confidence#': 406,\n",
              "  'stewardess#': 407,\n",
              "  'compliment#': 408,\n",
              "  'unbuttoned#': 409,\n",
              "  'hopelessly#': 410,\n",
              "  'friendship#': 411,\n",
              "  'volleyball#': 412,\n",
              "  'thoroughly#': 413,\n",
              "  'recovering#': 414,\n",
              "  'expression#': 415,\n",
              "  'boyfriends#': 416,\n",
              "  'waterproof#': 417,\n",
              "  'telephoned#': 418,\n",
              "  'altogether#': 419,\n",
              "  'overthrown#': 420,\n",
              "  'ambassador#': 421,\n",
              "  'unbearable#': 422,\n",
              "  'refreshing#': 423,\n",
              "  'themselves#': 424,\n",
              "  'cautiously#': 425,\n",
              "  'admiration#': 426,\n",
              "  'wheelchair#': 427,\n",
              "  'archeology#': 428,\n",
              "  'celebrated#': 429,\n",
              "  'conditions#': 430,\n",
              "  'occupation#': 431,\n",
              "  'compromise#': 432,\n",
              "  'department#': 433,\n",
              "  'employment#': 434,\n",
              "  'acceptable#': 435,\n",
              "  'attractive#': 436,\n",
              "  'successful#': 437,\n",
              "  'photograph': 438,\n",
              "  'handkerchi': 439,\n",
              "  'fantastic#': 440,\n",
              "  'seriously#': 441,\n",
              "  'apologize#': 442,\n",
              "  'overslept#': 443,\n",
              "  'attentive#': 444,\n",
              "  'confident#': 445,\n",
              "  'merciless#': 446,\n",
              "  'objective#': 447,\n",
              "  'realistic#': 448,\n",
              "  'succeeded#': 449,\n",
              "  'surrender#': 450,\n",
              "  'something#': 451,\n",
              "  'beautiful#': 452,\n",
              "  'thrilling#': 453,\n",
              "  'icelandic#': 454,\n",
              "  'easygoing#': 455,\n",
              "  'important#': 456,\n",
              "  'uninsured#': 457,\n",
              "  'applauded#': 458,\n",
              "  'exercised#': 459,\n",
              "  'exercises#': 460,\n",
              "  'graduated#': 461,\n",
              "  'hesitated#': 462,\n",
              "  'recovered#': 463,\n",
              "  'remembers#': 464,\n",
              "  'staggered#': 465,\n",
              "  'disagreed#': 466,\n",
              "  'hypocrite#': 467,\n",
              "  'everybody#': 468,\n",
              "  'afternoon#': 469,\n",
              "  'guarantee#': 470,\n",
              "  'wednesday#': 471,\n",
              "  'identical#': 472,\n",
              "  'listening#': 473,\n",
              "  'searching#': 474,\n",
              "  'gossiping#': 475,\n",
              "  'grumbling#': 476,\n",
              "  'resisting#': 477,\n",
              "  'screaming#': 478,\n",
              "  'quarreled#': 479,\n",
              "  'struggled#': 480,\n",
              "  'carefully#': 481,\n",
              "  'ethiopian#': 482,\n",
              "  'depressed#': 483,\n",
              "  'unmarried#': 484,\n",
              "  'mentioned#': 485,\n",
              "  'pressured#': 486,\n",
              "  'chickened#': 487,\n",
              "  'sunburned#': 488,\n",
              "  'outwitted#': 489,\n",
              "  'recognize#': 490,\n",
              "  'disgusted#': 491,\n",
              "  'skeptical#': 492,\n",
              "  'policeman#': 493,\n",
              "  'malaysian#': 494,\n",
              "  'breathing#': 495,\n",
              "  'christmas#': 496,\n",
              "  'brazilian#': 497,\n",
              "  'assertive#': 498,\n",
              "  'conscious#': 499,\n",
              "  'dangerous#': 500,\n",
              "  'newlyweds#': 501,\n",
              "  'accidents#': 502,\n",
              "  'invisible#': 503,\n",
              "  'croissant#': 504,\n",
              "  'terrified#': 505,\n",
              "  'tenacious#': 506,\n",
              "  'gentleman#': 507,\n",
              "  'flattered#': 508,\n",
              "  'powerless#': 509,\n",
              "  'refreshed#': 510,\n",
              "  'chemistry#': 511,\n",
              "  'hypocrisy#': 512,\n",
              "  'surprises#': 513,\n",
              "  'heartburn#': 514,\n",
              "  'australia#': 515,\n",
              "  'chocolate#': 516,\n",
              "  'languages#': 517,\n",
              "  'traveling#': 518,\n",
              "  'astronomy#': 519,\n",
              "  'breakfast#': 520,\n",
              "  'recommend#': 521,\n",
              "  'reachable#': 522,\n",
              "  'satisfied#': 523,\n",
              "  'shameless#': 524,\n",
              "  'surprised#': 525,\n",
              "  'confusing#': 526,\n",
              "  'debatable#': 527,\n",
              "  'dishonest#': 528,\n",
              "  'offensive#': 529,\n",
              "  'troubling#': 530,\n",
              "  'wonderful#': 531,\n",
              "  'abandoned#': 532,\n",
              "  'convinced#': 533,\n",
              "  'frightens#': 534,\n",
              "  'ambitious#': 535,\n",
              "  'available#': 536,\n",
              "  'brilliant#': 537,\n",
              "  'deceitful#': 538,\n",
              "  'desperate#': 539,\n",
              "  'different#': 540,\n",
              "  'eccentric#': 541,\n",
              "  'emotional#': 542,\n",
              "  'energetic#': 543,\n",
              "  'forgetful#': 544,\n",
              "  'improving#': 545,\n",
              "  'insincere#': 546,\n",
              "  'muttering#': 547,\n",
              "  'obsessive#': 548,\n",
              "  'perplexed#': 549,\n",
              "  'undecided#': 550,\n",
              "  'weakening#': 551,\n",
              "  'whistling#': 552,\n",
              "  'swordfish#': 553,\n",
              "  'disturbed#': 554,\n",
              "  'happening#': 555,\n",
              "  'conceited#': 556,\n",
              "  'motivated#': 557,\n",
              "  'practical#': 558,\n",
              "  'admission#': 559,\n",
              "  'religious#': 560,\n",
              "  'ambulance#': 561,\n",
              "  'champagne#': 562,\n",
              "  'goodnight#': 563,\n",
              "  'yesterday#': 564,\n",
              "  'biologist#': 565,\n",
              "  'daredevil#': 566,\n",
              "  'scientist#': 567,\n",
              "  'consented#': 568,\n",
              "  'nightmare#': 569,\n",
              "  'otherwise#': 570,\n",
              "  'corrected#': 571,\n",
              "  'expecting#': 572,\n",
              "  'difficult#': 573,\n",
              "  'enjoyable#': 574,\n",
              "  'expensive#': 575,\n",
              "  'attention#': 576,\n",
              "  'bothering#': 577,\n",
              "  'essential#': 578,\n",
              "  'continued#': 579,\n",
              "  'kidnapped#': 580,\n",
              "  'canadians#': 581,\n",
              "  'separated#': 582,\n",
              "  'delicious#': 583,\n",
              "  'extortion#': 584,\n",
              "  'gibberish#': 585,\n",
              "  'hilarious#': 586,\n",
              "  'spaghetti#': 587,\n",
              "  'allergies#': 588,\n",
              "  'arthritis#': 589,\n",
              "  'patiently#': 590,\n",
              "  'acquitted#': 591,\n",
              "  'dismissed#': 592,\n",
              "  'horrified#': 593,\n",
              "  'impressed#': 594,\n",
              "  'strangled#': 595,\n",
              "  'cultivate#': 596,\n",
              "  'mysteries#': 597,\n",
              "  'happiness#': 598,\n",
              "  'flammable#': 599,\n",
              "  'actresses#': 600,\n",
              "  'scratched#': 601,\n",
              "  'overthink#': 602,\n",
              "  'patronize#': 603,\n",
              "  'foolishly#': 604,\n",
              "  'footsteps#': 605,\n",
              "  'classmate#': 606,\n",
              "  'colleague#': 607,\n",
              "  'adventure#': 608,\n",
              "  'hedgehogs#': 609,\n",
              "  'fractured#': 610,\n",
              "  'nosebleed#': 611,\n",
              "  'toothache#': 612,\n",
              "  'challenge#': 613,\n",
              "  'extremely#': 614,\n",
              "  'misjudged#': 615,\n",
              "  'ignorance#': 616,\n",
              "  'worthless#': 617,\n",
              "  'necessary#': 618,\n",
              "  'alcoholic#': 619,\n",
              "  'godmother#': 620,\n",
              "  'professor#': 621,\n",
              "  'harassing#': 622,\n",
              "  'countdown#': 623,\n",
              "  'exhausted#': 624,\n",
              "  'shoelaces#': 625,\n",
              "  'comforted#': 626,\n",
              "  'contacted#': 627,\n",
              "  'described#': 628,\n",
              "  'cameraman#': 629,\n",
              "  'celebrity#': 630,\n",
              "  'communist#': 631,\n",
              "  'lifeguard#': 632,\n",
              "  'socialist#': 633,\n",
              "  'reassured#': 634,\n",
              "  'respected#': 635,\n",
              "  'ballistic#': 636,\n",
              "  'sacrifice#': 637,\n",
              "  'neighbors#': 638,\n",
              "  'agreement#': 639,\n",
              "  'motivates#': 640,\n",
              "  'elephants#': 641,\n",
              "  'contented#': 642,\n",
              "  'overrated#': 643,\n",
              "  'elaborate#': 644,\n",
              "  'sometimes#': 645,\n",
              "  'christian#': 646,\n",
              "  'decorated#': 647,\n",
              "  'forgotten#': 648,\n",
              "  'pretended#': 649,\n",
              "  'purchased#': 650,\n",
              "  'following#': 651,\n",
              "  'assistant#': 652,\n",
              "  'preparing#': 653,\n",
              "  'accompany#': 654,\n",
              "  'interrupt#': 655,\n",
              "  'ostriches#': 656,\n",
              "  'believing#': 657,\n",
              "  'imitation#': 658,\n",
              "  'intention#': 659,\n",
              "  'deserters#': 660,\n",
              "  'newspaper#': 661,\n",
              "  'gentlemen#': 662,\n",
              "  'cartwheel#': 663,\n",
              "  'halloween#': 664,\n",
              "  'architect#': 665,\n",
              "  'brunettes#': 666,\n",
              "  'cigarette#': 667,\n",
              "  'complains#': 668,\n",
              "  'translate#': 669,\n",
              "  'umbrellas#': 670,\n",
              "  'ourselves#': 671,\n",
              "  'correctly#': 672,\n",
              "  'imitating#': 673,\n",
              "  'excellent#': 674,\n",
              "  'attempted#': 675,\n",
              "  'committed#': 676,\n",
              "  'daughters#': 677,\n",
              "  'sensitive#': 678,\n",
              "  'ridiculed#': 679,\n",
              "  'influence#': 680,\n",
              "  'hopefully#': 681,\n",
              "  'fingertip#': 682,\n",
              "  'willingly#': 683,\n",
              "  'lightning#': 684,\n",
              "  'boyfriend#': 685,\n",
              "  'depending#': 686,\n",
              "  'excessive#': 687,\n",
              "  'marvelous#': 688,\n",
              "  'thankless#': 689,\n",
              "  'obviously#': 690,\n",
              "  'peninsula#': 691,\n",
              "  'supported#': 692,\n",
              "  'telephone#': 693,\n",
              "  'duplicate#': 694,\n",
              "  'permitted#': 695,\n",
              "  'unhealthy#': 696,\n",
              "  'collapsed#': 697,\n",
              "  'exchanged#': 698,\n",
              "  'apartment#': 699,\n",
              "  'collected#': 700,\n",
              "  'authority#': 701,\n",
              "  'defendant#': 702,\n",
              "  'petrified#': 703,\n",
              "  'anxiously#': 704,\n",
              "  'cellphone#': 705,\n",
              "  'intuition#': 706,\n",
              "  'poisoning#': 707,\n",
              "  'sabotaged#': 708,\n",
              "  'discussed#': 709,\n",
              "  'dignified#': 710,\n",
              "  'emergency#': 711,\n",
              "  'embarrass#': 712,\n",
              "  'scapegoat#': 713,\n",
              "  'seatbelts#': 714,\n",
              "  'compasses#': 715,\n",
              "  'impatient#': 716,\n",
              "  'strangers#': 717,\n",
              "  'continent#': 718,\n",
              "  'explained#': 719,\n",
              "  'suspicion#': 720,\n",
              "  'hurriedly#': 721,\n",
              "  'beginning#': 722,\n",
              "  'precooked#': 723,\n",
              "  'insurance#': 724,\n",
              "  'frankness#': 725,\n",
              "  'musicians#': 726,\n",
              "  'postponed#': 727,\n",
              "  'attracted#': 728,\n",
              "  'naturally#': 729,\n",
              "  'perfectly#': 730,\n",
              "  'stressful#': 731,\n",
              "  'sentences#': 732,\n",
              "  'vibrating#': 733,\n",
              "  'seventeen#': 734,\n",
              "  'promising#': 735,\n",
              "  'extensive#': 736,\n",
              "  'limitless#': 737,\n",
              "  'situation#': 738,\n",
              "  'confessed#': 739,\n",
              "  'unanimous#': 740,\n",
              "  'leftovers#': 741,\n",
              "  'conundrum#': 742,\n",
              "  'consoling#': 743,\n",
              "  'divorcing#': 744,\n",
              "  'competent#': 745,\n",
              "  'dexterous#': 746,\n",
              "  'ingenious#': 747,\n",
              "  'sarcastic#': 748,\n",
              "  'kilograms#': 749,\n",
              "  'triathlon#': 750,\n",
              "  'customers#': 751,\n",
              "  'president#': 752,\n",
              "  'sunscreen#': 753,\n",
              "  'witnesses#': 754,\n",
              "  'irritated#': 755,\n",
              "  'recording#': 756,\n",
              "  'destroyed#': 757,\n",
              "  'magazines#': 758,\n",
              "  'proofread#': 759,\n",
              "  'bulgarian#': 760,\n",
              "  'shoulders#': 761,\n",
              "  'violinist#': 762,\n",
              "  'swallowed#': 763,\n",
              "  'discarded#': 764,\n",
              "  'honeymoon#': 765,\n",
              "  'criticize#': 766,\n",
              "  'shellfish#': 767,\n",
              "  'inherited#': 768,\n",
              "  'classical#': 769,\n",
              "  'misplaced#': 770,\n",
              "  'signature#': 771,\n",
              "  'accordion#': 772,\n",
              "  'regretted#': 773,\n",
              "  'reception#': 774,\n",
              "  'somewhere#': 775,\n",
              "  'objection#': 776,\n",
              "  'jerusalem#': 777,\n",
              "  'lunchtime#': 778,\n",
              "  'procedure#': 779,\n",
              "  'introduce#': 780,\n",
              "  'preschool#': 781,\n",
              "  'crybabies#': 782,\n",
              "  'resembles#': 783,\n",
              "  'marketing#': 784,\n",
              "  'glamorous#': 785,\n",
              "  'silkworms#': 786,\n",
              "  'squirrels#': 787,\n",
              "  'defective#': 788,\n",
              "  'undressed#': 789,\n",
              "  'explosion#': 790,\n",
              "  'reminisce#': 791,\n",
              "  'americans#': 792,\n",
              "  'rainproof#': 793,\n",
              "  'incorrect#': 794,\n",
              "  'disguised#': 795,\n",
              "  'questions#': 796,\n",
              "  'obstinate#': 797,\n",
              "  'neglected#': 798,\n",
              "  'snowboard#': 799,\n",
              "  'sharpened#': 800,\n",
              "  'unplugged#': 801,\n",
              "  'postcards#': 802,\n",
              "  'housework#': 803,\n",
              "  'cafeteria#': 804,\n",
              "  'librarian#': 805,\n",
              "  'interfere#': 806,\n",
              "  'whispered#': 807,\n",
              "  'incurable#': 808,\n",
              "  'relatives#': 809,\n",
              "  'referring#': 810,\n",
              "  'mandatory#': 811,\n",
              "  'forearmed#': 812,\n",
              "  'promotion#': 813,\n",
              "  'bookshelf#': 814,\n",
              "  'instantly#': 815,\n",
              "  'painfully#': 816,\n",
              "  'witnessed#': 817,\n",
              "  'childhood#': 818,\n",
              "  'secretary#': 819,\n",
              "  'stretched#': 820,\n",
              "  'hospitals#': 821,\n",
              "  'concerned#': 822,\n",
              "  'repairing#': 823,\n",
              "  'resigning#': 824,\n",
              "  'increased#': 825,\n",
              "  'intrusion#': 826,\n",
              "  'hazelnuts#': 827,\n",
              "  'torturing#': 828,\n",
              "  'whichever#': 829,\n",
              "  'distracts#': 830,\n",
              "  'furniture#': 831,\n",
              "  'ceaseless#': 832,\n",
              "  'snowstorm#': 833,\n",
              "  'congested#': 834,\n",
              "  'railroads#': 835,\n",
              "  'originals#': 836,\n",
              "  'gathering#': 837,\n",
              "  'flattened#': 838,\n",
              "  'passports#': 839,\n",
              "  'terrifies#': 840,\n",
              "  'certainly#': 841,\n",
              "  'guitarist#': 842,\n",
              "  'clubhouse#': 843,\n",
              "  'warehouse#': 844,\n",
              "  'headaches#': 845,\n",
              "  'responded#': 846,\n",
              "  'reluctant#': 847,\n",
              "  'impounded#': 848,\n",
              "  'lifeboats#': 849,\n",
              "  'strongest#': 850,\n",
              "  'punishing#': 851,\n",
              "  'eavesdrop#': 852,\n",
              "  'sustained#': 853,\n",
              "  'ceasefire#': 854,\n",
              "  'porcelain#': 855,\n",
              "  'distances#': 856,\n",
              "  'buffaloes#': 857,\n",
              "  'usernames#': 858,\n",
              "  'dependent#': 859,\n",
              "  'daughter#': 860,\n",
              "  'promised#': 861,\n",
              "  'graceful#': 862,\n",
              "  'defeated#': 863,\n",
              "  'children#': 864,\n",
              "  'approved#': 865,\n",
              "  'pleasant#': 866,\n",
              "  'sociable#': 867,\n",
              "  'breaking#': 868,\n",
              "  'occupied#': 869,\n",
              "  'adequate#': 870,\n",
              "  'presents#': 871,\n",
              "  'controver': 872,\n",
              "  'contribut': 873,\n",
              "  'terrific#': 874,\n",
              "  'chuckled#': 875,\n",
              "  'disagree#': 876,\n",
              "  'remember#': 877,\n",
              "  'screamed#': 878,\n",
              "  'creative#': 879,\n",
              "  'discreet#': 880,\n",
              "  'merciful#': 881,\n",
              "  'prepared#': 882,\n",
              "  'punctual#': 883,\n",
              "  'sensible#': 884,\n",
              "  'specific#': 885,\n",
              "  'thorough#': 886,\n",
              "  'tolerant#': 887,\n",
              "  'vigilant#': 888,\n",
              "  'watchful#': 889,\n",
              "  'straight#': 890,\n",
              "  'resigned#': 891,\n",
              "  'happened#': 892,\n",
              "  'memorize#': 893,\n",
              "  'anything#': 894,\n",
              "  'describe#': 895,\n",
              "  'upstairs#': 896,\n",
              "  'annoying#': 897,\n",
              "  'arrogant#': 898,\n",
              "  'horrible#': 899,\n",
              "  'romantic#': 900,\n",
              "  'anorexic#': 901,\n",
              "  'drowning#': 902,\n",
              "  'educated#': 903,\n",
              "  'famished#': 904,\n",
              "  'freezing#': 905,\n",
              "  'grieving#': 906,\n",
              "  'relieved#': 907,\n",
              "  'starving#': 908,\n",
              "  'thirteen#': 909,\n",
              "  'answered#': 910,\n",
              "  'approves#': 911,\n",
              "  'canceled#': 912,\n",
              "  'enlisted#': 913,\n",
              "  'finished#': 914,\n",
              "  'flinched#': 915,\n",
              "  'insisted#': 916,\n",
              "  'listened#': 917,\n",
              "  'panicked#': 918,\n",
              "  'relented#': 919,\n",
              "  'shrugged#': 920,\n",
              "  'stutters#': 921,\n",
              "  'survived#': 922,\n",
              "  'vanished#': 923,\n",
              "  'dreaming#': 924,\n",
              "  'included#': 925,\n",
              "  'security#': 926,\n",
              "  'tomorrow#': 927,\n",
              "  'everyone#': 928,\n",
              "  'adorable#': 929,\n",
              "  'demented#': 930,\n",
              "  'studying#': 931,\n",
              "  'yourself#': 932,\n",
              "  'acquired#': 933,\n",
              "  'japanese#': 934,\n",
              "  'borrowed#': 935,\n",
              "  'deserved#': 936,\n",
              "  'designed#': 937,\n",
              "  'saturday#': 938,\n",
              "  'official#': 939,\n",
              "  'paddling#': 940,\n",
              "  'gambling#': 941,\n",
              "  'somebody#': 942,\n",
              "  'positive#': 943,\n",
              "  'together#': 944,\n",
              "  'babbling#': 945,\n",
              "  'fighting#': 946,\n",
              "  'meddling#': 947,\n",
              "  'shooting#': 948,\n",
              "  'shouting#': 949,\n",
              "  'worrying#': 950,\n",
              "  'embraced#': 951,\n",
              "  'nonsense#': 952,\n",
              "  'complain#': 953,\n",
              "  'holidays#': 954,\n",
              "  'deceived#': 955,\n",
              "  'dislikes#': 956,\n",
              "  'bankrupt#': 957,\n",
              "  'homeless#': 958,\n",
              "  'outgoing#': 959,\n",
              "  'respects#': 960,\n",
              "  'business#': 961,\n",
              "  'believed#': 962,\n",
              "  'homesick#': 963,\n",
              "  'punished#': 964,\n",
              "  'laughing#': 965,\n",
              "  'restless#': 966,\n",
              "  'salesman#': 967,\n",
              "  'american#': 968,\n",
              "  'canadian#': 969,\n",
              "  'pregnant#': 970,\n",
              "  'stubborn#': 971,\n",
              "  'appeared#': 972,\n",
              "  'counting#': 973,\n",
              "  'charming#': 974,\n",
              "  'confused#': 975,\n",
              "  'stranded#': 976,\n",
              "  'sweating#': 977,\n",
              "  'swimming#': 978,\n",
              "  'thrilled#': 979,\n",
              "  'hopeless#': 980,\n",
              "  'speaking#': 981,\n",
              "  'watching#': 982,\n",
              "  'capsized#': 983,\n",
              "  'betrayed#': 984,\n",
              "  'cheating#': 985,\n",
              "  'standing#': 986,\n",
              "  'freshman#': 987,\n",
              "  'helpless#': 988,\n",
              "  'terrible#': 989,\n",
              "  'football#': 990,\n",
              "  'politics#': 991,\n",
              "  'raccoons#': 992,\n",
              "  'reptiles#': 993,\n",
              "  'tomatoes#': 994,\n",
              "  'imagined#': 995,\n",
              "  'cartoons#': 996,\n",
              "  'climbing#': 997,\n",
              "  'sleeping#': 998,\n",
              "  'teaching#': 999,\n",
              "  'interest#': 1000,\n",
              "  'comedies#': 1001,\n",
              "  'eggplant#': 1002,\n",
              "  'weddings#': 1003,\n",
              "  ...},\n",
              " {'bienintencionados#': 4,\n",
              "  'suficientemente#': 5,\n",
              "  'resplandeciente#': 6,\n",
              "  'estadounidenses#': 7,\n",
              "  'frecuentemente#': 8,\n",
              "  'estupendamente#': 9,\n",
              "  'sobrevivisteis#': 10,\n",
              "  'estadounidense#': 11,\n",
              "  'sobreviviremos#': 12,\n",
              "  'verdaderamente#': 13,\n",
              "  'cuidadosamente#': 14,\n",
              "  'desaparecieron#': 15,\n",
              "  'inmediatamente#': 16,\n",
              "  'perfectamente#': 17,\n",
              "  'desconcertado#': 18,\n",
              "  'compartiremos#': 19,\n",
              "  'identificarme#': 20,\n",
              "  'detenidamente#': 21,\n",
              "  'sobrevivieron#': 22,\n",
              "  'preguntaremos#': 23,\n",
              "  'desorientados#': 24,\n",
              "  'comprometidos#': 25,\n",
              "  'conseguiremos#': 26,\n",
              "  'sencillamente#': 27,\n",
              "  'desafortunado#': 28,\n",
              "  'averiguaremos#': 29,\n",
              "  'correctamente#': 30,\n",
              "  'comprendiendo#': 31,\n",
              "  'despreocupada#': 32,\n",
              "  'responsabiliz#': 33,\n",
              "  'recientemente#': 34,\n",
              "  'universitario#': 35,\n",
              "  'relativamente#': 36,\n",
              "  'enloqueciendo#': 37,\n",
              "  'chismorreando#': 38,\n",
              "  'entusiasmados#': 39,\n",
              "  'encontraremos#': 40,\n",
              "  'notificaremos#': 41,\n",
              "  'historiadores#': 42,\n",
              "  'completamente#': 43,\n",
              "  'profundamente#': 44,\n",
              "  'remordimiento#': 45,\n",
              "  'sobreactuando#': 46,\n",
              "  'impresionante#': 47,\n",
              "  'probablemente#': 48,\n",
              "  'investiguemos#': 49,\n",
              "  'indispensable#': 50,\n",
              "  'entristecedor#': 51,\n",
              "  'reemplazable#': 52,\n",
              "  'inconsciente#': 53,\n",
              "  'intentaremos#': 54,\n",
              "  'aburrimiento#': 55,\n",
              "  'reemplazadlo#': 56,\n",
              "  'fracasaremos#': 57,\n",
              "  'trabajaremos#': 58,\n",
              "  'comprometida#': 59,\n",
              "  'quisquilloso#': 60,\n",
              "  'encontrarnos#': 61,\n",
              "  'sobrevivimos#': 62,\n",
              "  'conduciremos#': 63,\n",
              "  'desasosegado#': 64,\n",
              "  'entusiasmado#': 65,\n",
              "  'desahuciados#': 66,\n",
              "  'prometisteis#': 67,\n",
              "  'sobreviviste#': 68,\n",
              "  'inteligentes#': 69,\n",
              "  'irrespetuoso#': 70,\n",
              "  'estornudando#': 71,\n",
              "  'impresionada#': 72,\n",
              "  'impresionado#': 73,\n",
              "  'construyeron#': 74,\n",
              "  'esconderemos#': 75,\n",
              "  'mentalizados#': 76,\n",
              "  'extrovertido#': 77,\n",
              "  'principiante#': 78,\n",
              "  'desvistiendo#': 79,\n",
              "  'acostumbrado#': 80,\n",
              "  'acostumbrada#': 81,\n",
              "  'practiquemos#': 82,\n",
              "  'descubrieron#': 83,\n",
              "  'descompuesto#': 84,\n",
              "  'espeluznante#': 85,\n",
              "  'cerdomarrano#': 86,\n",
              "  'identificaci#': 87,\n",
              "  'extrovertida#': 88,\n",
              "  'desorientado#': 89,\n",
              "  'traicionaste#': 90,\n",
              "  'envejeciendo#': 91,\n",
              "  'educadamente#': 92,\n",
              "  'decepcionado#': 93,\n",
              "  'cordialmente#': 94,\n",
              "  'comtemplaron#': 95,\n",
              "  'descendieron#': 96,\n",
              "  'involucrados#': 97,\n",
              "  'tuberculosis#': 98,\n",
              "  'desmemoriado#': 99,\n",
              "  'delincuencia#': 100,\n",
              "  'desilusiones#': 101,\n",
              "  'introvertido#': 102,\n",
              "  'encolerizado#': 103,\n",
              "  'concentrando#': 104,\n",
              "  'confidencial#': 105,\n",
              "  'entumecieron#': 106,\n",
              "  'desaparecido#': 107,\n",
              "  'aterrorizaba#': 108,\n",
              "  'encontrarme#': 109,\n",
              "  'responsable#': 110,\n",
              "  'dependiente#': 111,\n",
              "  'tunadamente#': 112,\n",
              "  'escrupuloso#': 113,\n",
              "  'fuertemente#': 114,\n",
              "  'preocupamos#': 115,\n",
              "  'bienvenidos#': 116,\n",
              "  'bienvenidas#': 117,\n",
              "  'preguntales#': 118,\n",
              "  'respondedme#': 119,\n",
              "  'conversamos#': 120,\n",
              "  'preguntadle#': 121,\n",
              "  'inteligente#': 122,\n",
              "  'renunciemos#': 123,\n",
              "  'conversemos#': 124,\n",
              "  'comentarios#': 125,\n",
              "  'mantuvieron#': 126,\n",
              "  'esperaremos#': 127,\n",
              "  'trescientos#': 128,\n",
              "  'despidieron#': 129,\n",
              "  'mentalizado#': 130,\n",
              "  'descansando#': 131,\n",
              "  'obedecieron#': 132,\n",
              "  'necesitamos#': 133,\n",
              "  'exactamente#': 134,\n",
              "  'intranquilo#': 135,\n",
              "  'concienzudo#': 136,\n",
              "  'funcionando#': 137,\n",
              "  'conduciendo#': 138,\n",
              "  'escribiendo#': 139,\n",
              "  'atentamente#': 140,\n",
              "  'estrellaron#': 141,\n",
              "  'abandonaron#': 142,\n",
              "  'desistieron#': 143,\n",
              "  'veterinario#': 144,\n",
              "  'despertalos#': 145,\n",
              "  'encontramos#': 146,\n",
              "  'conseguimos#': 147,\n",
              "  'hambrientos#': 148,\n",
              "  'desperdicio#': 149,\n",
              "  'prometieron#': 150,\n",
              "  'respetuosos#': 151,\n",
              "  'descomponlo#': 152,\n",
              "  'emocionante#': 153,\n",
              "  'consciencia#': 154,\n",
              "  'menosprecio#': 155,\n",
              "  'desesperado#': 156,\n",
              "  'desesperada#': 157,\n",
              "  'horrorizado#': 158,\n",
              "  'horrorizada#': 159,\n",
              "  'corresponde#': 160,\n",
              "  'preguntarle#': 161,\n",
              "  'encontraron#': 162,\n",
              "  'preguntamos#': 163,\n",
              "  'conseguirlo#': 164,\n",
              "  'demostrarlo#': 165,\n",
              "  'simplemente#': 166,\n",
              "  'divirtiendo#': 167,\n",
              "  'escondiendo#': 168,\n",
              "  'desempleado#': 169,\n",
              "  'desempleada#': 170,\n",
              "  'maravilloso#': 171,\n",
              "  'continuemos#': 172,\n",
              "  'aplaudieron#': 173,\n",
              "  'preguntaron#': 174,\n",
              "  'discutieron#': 175,\n",
              "  'estropeados#': 176,\n",
              "  'avergonzado#': 177,\n",
              "  'concentrado#': 178,\n",
              "  'encontrarlo#': 179,\n",
              "  'presentamos#': 180,\n",
              "  'divorciados#': 181,\n",
              "  'pensamiento#': 182,\n",
              "  'ciertamente#': 183,\n",
              "  'entretenido#': 184,\n",
              "  'afortunados#': 185,\n",
              "  'superficial#': 186,\n",
              "  'inservibles#': 187,\n",
              "  'felicidades#': 188,\n",
              "  'emborraches#': 189,\n",
              "  'interfieras#': 190,\n",
              "  'interrumpas#': 191,\n",
              "  'interesante#': 192,\n",
              "  'traicionada#': 193,\n",
              "  'desamparado#': 194,\n",
              "  'petrificado#': 195,\n",
              "  'recompensar#': 196,\n",
              "  'farfullando#': 197,\n",
              "  'irrelevante#': 198,\n",
              "  'refrescante#': 199,\n",
              "  'practicando#': 200,\n",
              "  'averiguarlo#': 201,\n",
              "  'descansemos#': 202,\n",
              "  'entendieron#': 203,\n",
              "  'equivocados#': 204,\n",
              "  'equivocadas#': 205,\n",
              "  'discutiendo#': 206,\n",
              "  'preocupados#': 207,\n",
              "  'aprendiendo#': 208,\n",
              "  'compartimos#': 209,\n",
              "  'detendremos#': 210,\n",
              "  'visitaremos#': 211,\n",
              "  'canadienses#': 212,\n",
              "  'disponibles#': 213,\n",
              "  'imparciales#': 214,\n",
              "  'organizados#': 215,\n",
              "  'prisioneros#': 216,\n",
              "  'satisfechos#': 217,\n",
              "  'preguntaste#': 218,\n",
              "  'estudiantes#': 219,\n",
              "  'encontrarla#': 220,\n",
              "  'descubrirlo#': 221,\n",
              "  'encontraste#': 222,\n",
              "  'universidad#': 223,\n",
              "  'persistente#': 224,\n",
              "  'historiador#': 225,\n",
              "  'estupefacto#': 226,\n",
              "  'computadora#': 227,\n",
              "  'divorciarme#': 228,\n",
              "  'registrando#': 229,\n",
              "  'precipitaci#': 230,\n",
              "  'alegremente#': 231,\n",
              "  'pellizcarme#': 232,\n",
              "  'entrenadora#': 233,\n",
              "  'manipulador#': 234,\n",
              "  'involucrado#': 235,\n",
              "  'socorristas#': 236,\n",
              "  'renunciaste#': 237,\n",
              "  'defraudaste#': 238,\n",
              "  'sorprendido#': 239,\n",
              "  'sorprendida#': 240,\n",
              "  'impacientes#': 241,\n",
              "  'propietario#': 242,\n",
              "  'decepciones#': 243,\n",
              "  'arrodillaos#': 244,\n",
              "  'encarcelado#': 245,\n",
              "  'complejidad#': 246,\n",
              "  'vegetariano#': 247,\n",
              "  'adelgazando#': 248,\n",
              "  'diccionario#': 249,\n",
              "  'vivificante#': 250,\n",
              "  'reconsidera#': 251,\n",
              "  'desgraciada#': 252,\n",
              "  'amargamente#': 253,\n",
              "  'hiperactiva#': 254,\n",
              "  'preguntarme#': 255,\n",
              "  'fundamental#': 256,\n",
              "  'millonario#': 257,\n",
              "  'razonables#': 258,\n",
              "  'preocupado#': 259,\n",
              "  'competente#': 260,\n",
              "  'enterraron#': 261,\n",
              "  'entimiento#': 262,\n",
              "  'afortunada#': 263,\n",
              "  'organizado#': 264,\n",
              "  'desconsider': 265,\n",
              "  'capacitada#': 266,\n",
              "  'entendiste#': 267,\n",
              "  'trabajando#': 268,\n",
              "  'diecinueve#': 269,\n",
              "  'procuramos#': 270,\n",
              "  'despertate#': 271,\n",
              "  'encontralo#': 272,\n",
              "  'encuentren#': 273,\n",
              "  'intentamos#': 274,\n",
              "  'marcharnos#': 275,\n",
              "  'alcanzaron#': 276,\n",
              "  'arrestadlo#': 277,\n",
              "  'capturadlo#': 278,\n",
              "  'intentadlo#': 279,\n",
              "  'intentaste#': 280,\n",
              "  'equivocada#': 281,\n",
              "  'respondele#': 282,\n",
              "  'encantador#': 283,\n",
              "  'intentando#': 284,\n",
              "  'esforzando#': 285,\n",
              "  'anochecido#': 286,\n",
              "  'desistamos#': 287,\n",
              "  'trabajemos#': 288,\n",
              "  'consciente#': 289,\n",
              "  'intentaron#': 290,\n",
              "  'intentarlo#': 291,\n",
              "  'divertimos#': 292,\n",
              "  'ayudaremos#': 293,\n",
              "  'cantaremos#': 294,\n",
              "  'terminamos#': 295,\n",
              "  'preparados#': 296,\n",
              "  'especifica#': 297,\n",
              "  'exhaustivo#': 298,\n",
              "  'esconderme#': 299,\n",
              "  'equivocado#': 300,\n",
              "  'curiosidad#': 301,\n",
              "  'emocionado#': 302,\n",
              "  'emocionada#': 303,\n",
              "  'preocupada#': 304,\n",
              "  'estropeado#': 305,\n",
              "  'comencemos#': 306,\n",
              "  'festejemos#': 307,\n",
              "  'satisfecho#': 308,\n",
              "  'disgustado#': 309,\n",
              "  'despertalo#': 310,\n",
              "  'lentamente#': 311,\n",
              "  'trabajamos#': 312,\n",
              "  'prometimos#': 313,\n",
              "  'recordamos#': 314,\n",
              "  'despiertos#': 315,\n",
              "  'arruinados#': 316,\n",
              "  'desmayaron#': 317,\n",
              "  'desmayaste#': 318,\n",
              "  'conseguido#': 319,\n",
              "  'encuentras#': 320,\n",
              "  'despiadado#': 321,\n",
              "  'describilo#': 322,\n",
              "  'arreglarlo#': 323,\n",
              "  'desconozco#': 324,\n",
              "  'necesitaba#': 325,\n",
              "  'encontraba#': 326,\n",
              "  'confundido#': 327,\n",
              "  'confundida#': 328,\n",
              "  'divorciada#': 329,\n",
              "  'dubitativo#': 330,\n",
              "  'agradecida#': 331,\n",
              "  'gravemente#': 332,\n",
              "  'embarazada#': 333,\n",
              "  'embarazado#': 334,\n",
              "  'estudiando#': 335,\n",
              "  'suficiente#': 336,\n",
              "  'repugnante#': 337,\n",
              "  'escuchemos#': 338,\n",
              "  'terminaron#': 339,\n",
              "  'agradecido#': 340,\n",
              "  'nuevamente#': 341,\n",
              "  'vitorearon#': 342,\n",
              "  'encuentran#': 343,\n",
              "  'encueroles#': 344,\n",
              "  'tartamudea#': 345,\n",
              "  'preparamos#': 346,\n",
              "  'almorzamos#': 347,\n",
              "  'lastimados#': 348,\n",
              "  'escondidos#': 349,\n",
              "  'reventados#': 350,\n",
              "  'bienvenido#': 351,\n",
              "  'bienvenida#': 352,\n",
              "  'maleducado#': 353,\n",
              "  'prometiste#': 354,\n",
              "  'despedidos#': 355,\n",
              "  'despedidas#': 356,\n",
              "  'espabilado#': 357,\n",
              "  'embriagado#': 358,\n",
              "  'respetuoso#': 359,\n",
              "  'participar#': 360,\n",
              "  'desfalleci#': 361,\n",
              "  'desesperes#': 362,\n",
              "  'estrellado#': 363,\n",
              "  'consigueme#': 364,\n",
              "  'constipado#': 365,\n",
              "  'pertenezco#': 366,\n",
              "  'finalmente#': 367,\n",
              "  'acatarrado#': 368,\n",
              "  'rodilleras#': 369,\n",
              "  'naturaleza#': 370,\n",
              "  'administro#': 371,\n",
              "  'senderismo#': 372,\n",
              "  'despertado#': 373,\n",
              "  'permitirlo#': 374,\n",
              "  'estudiante#': 375,\n",
              "  'olvidadizo#': 376,\n",
              "  'impaciente#': 377,\n",
              "  'importante#': 378,\n",
              "  'escuchando#': 379,\n",
              "  'hambriento#': 380,\n",
              "  'encontrado#': 381,\n",
              "  'prosigamos#': 382,\n",
              "  'demandemos#': 383,\n",
              "  'levantaron#': 384,\n",
              "  'cancelaron#': 385,\n",
              "  'arruinadas#': 386,\n",
              "  'incorrecto#': 387,\n",
              "  'descansado#': 388,\n",
              "  'delgaducho#': 389,\n",
              "  'contratado#': 390,\n",
              "  'afortunado#': 391,\n",
              "  'condenados#': 392,\n",
              "  'disparamos#': 393,\n",
              "  'entendemos#': 394,\n",
              "  'intrigados#': 395,\n",
              "  'prometidos#': 396,\n",
              "  'enamorados#': 397,\n",
              "  'especiales#': 398,\n",
              "  'dispararon#': 399,\n",
              "  'calificado#': 400,\n",
              "  'levantarte#': 401,\n",
              "  'vacaciones#': 402,\n",
              "  'canadiense#': 403,\n",
              "  'levantarme#': 404,\n",
              "  'arrestaron#': 405,\n",
              "  'corazonada#': 406,\n",
              "  'galletitas#': 407,\n",
              "  'cigarrillo#': 408,\n",
              "  'respuestas#': 409,\n",
              "  'cachorrito#': 410,\n",
              "  'ventilador#': 411,\n",
              "  'prisionero#': 412,\n",
              "  'interesado#': 413,\n",
              "  'interesada#': 414,\n",
              "  'preparando#': 415,\n",
              "  'desnudando#': 416,\n",
              "  'demandaron#': 417,\n",
              "  'redundante#': 418,\n",
              "  'arriesgado#': 419,\n",
              "  'permanezca#': 420,\n",
              "  'simplifica#': 421,\n",
              "  'escritorio#': 422,\n",
              "  'claramente#': 423,\n",
              "  'comenzamos#': 424,\n",
              "  'verdaderas#': 425,\n",
              "  'regresaron#': 426,\n",
              "  'encantaste#': 427,\n",
              "  'encantabas#': 428,\n",
              "  'arruinaron#': 429,\n",
              "  'esforzaron#': 430,\n",
              "  'paralizado#': 431,\n",
              "  'ilusionado#': 432,\n",
              "  'perdonamos#': 433,\n",
              "  'estudiamos#': 434,\n",
              "  'enmarcados#': 435,\n",
              "  'llamaremos#': 436,\n",
              "  'pintaremos#': 437,\n",
              "  'salvaremos#': 438,\n",
              "  'confiables#': 439,\n",
              "  'minuciosos#': 440,\n",
              "  'levantamos#': 441,\n",
              "  'observando#': 442,\n",
              "  'observamos#': 443,\n",
              "  'caprichoso#': 444,\n",
              "  'inservible#': 445,\n",
              "  'aburriendo#': 446,\n",
              "  'demandaste#': 447,\n",
              "  'estuvieron#': 448,\n",
              "  'desafinado#': 449,\n",
              "  'sobrevivir#': 450,\n",
              "  'comediante#': 451,\n",
              "  'humillante#': 452,\n",
              "  'soportarlo#': 453,\n",
              "  'deshacerlo#': 454,\n",
              "  'berenjenas#': 455,\n",
              "  'advertirle#': 456,\n",
              "  'campanilla#': 457,\n",
              "  'totalmente#': 458,\n",
              "  'comprender#': 459,\n",
              "  'carpintero#': 460,\n",
              "  'salvavidas#': 461,\n",
              "  'suplicando#': 462,\n",
              "  'implorando#': 463,\n",
              "  'respirando#': 464,\n",
              "  'artificial#': 465,\n",
              "  'inevitable#': 466,\n",
              "  'celebremos#': 467,\n",
              "  'remontemos#': 468,\n",
              "  'barriletes#': 469,\n",
              "  'intentemos#': 470,\n",
              "  'desapareci#': 471,\n",
              "  'entrometas#': 472,\n",
              "  'estupendos#': 473,\n",
              "  'aguardando#': 474,\n",
              "  'divorciado#': 475,\n",
              "  'atarantado#': 476,\n",
              "  'meticuloso#': 477,\n",
              "  'entrenando#': 478,\n",
              "  'suavemente#': 479,\n",
              "  'profesores#': 480,\n",
              "  'arrestamos#': 481,\n",
              "  'asesinados#': 482,\n",
              "  'perteneces#': 483,\n",
              "  'accidentes#': 484,\n",
              "  'lastimando#': 485,\n",
              "  'cualquiera#': 486,\n",
              "  'levantaros#': 487,\n",
              "  'sabiamente#': 488,\n",
              "  'controlate#': 489,\n",
              "  'divertiste#': 490,\n",
              "  'advertiste#': 491,\n",
              "  'desanimado#': 492,\n",
              "  'desanimada#': 493,\n",
              "  'aterroriza#': 494,\n",
              "  'extranjero#': 495,\n",
              "  'masoquista#': 496,\n",
              "  'convertido#': 497,\n",
              "  'preguntado#': 498,\n",
              "  'refrescado#': 499,\n",
              "  'adelantado#': 500,\n",
              "  'frecuencia#': 501,\n",
              "  'violoncelo#': 502,\n",
              "  'recomiendo#': 503,\n",
              "  'arrepiento#': 504,\n",
              "  'almorzando#': 505,\n",
              "  'disponible#': 506,\n",
              "  'embaucando#': 507,\n",
              "  'sospechoso#': 508,\n",
              "  'contagioso#': 509,\n",
              "  'satisfecha#': 510,\n",
              "  'lloviznaba#': 511,\n",
              "  'complicado#': 512,\n",
              "  'oscurecido#': 513,\n",
              "  'improbable#': 514,\n",
              "  'almorcemos#': 515,\n",
              "  'contestame#': 516,\n",
              "  'compartilo#': 517,\n",
              "  'idolatraba#': 518,\n",
              "  'calcetines#': 519,\n",
              "  'arduamente#': 520,\n",
              "  'discutible#': 521,\n",
              "  'deshonesto#': 522,\n",
              "  'observaron#': 523,\n",
              "  'degradaron#': 524,\n",
              "  'desprecian#': 525,\n",
              "  'entrenador#': 526,\n",
              "  'maquinador#': 527,\n",
              "  'despistado#': 528,\n",
              "  'murmurando#': 529,\n",
              "  'zancadille#': 530,\n",
              "  'competimos#': 531,\n",
              "  'dependemos#': 532,\n",
              "  'molestamos#': 533,\n",
              "  'escuchamos#': 534,\n",
              "  'retirarnos#': 535,\n",
              "  'encallados#': 536,\n",
              "  'rescatados#': 537,\n",
              "  'hablaremos#': 538,\n",
              "  'estacionar#': 539,\n",
              "  'perturbado#': 540,\n",
              "  'lastimaste#': 541,\n",
              "  'equivoques#': 542,\n",
              "  'pasatiempo#': 543,\n",
              "  'enrojecida#': 544,\n",
              "  'torrencial#': 545,\n",
              "  'molestando#': 546,\n",
              "  'americanos#': 547,\n",
              "  'olvidadiza#': 548,\n",
              "  'apresurado#': 549,\n",
              "  'preguntale#': 550,\n",
              "  'comprendes#': 551,\n",
              "  'despiertes#': 552,\n",
              "  'formulario#': 553,\n",
              "  'influyente#': 554,\n",
              "  'pantalones#': 555,\n",
              "  'barandilla#': 556,\n",
              "  'destrozado#': 557,\n",
              "  'consolarla#': 558,\n",
              "  'computador#': 559,\n",
              "  'inventarlo#': 560,\n",
              "  'california#': 561,\n",
              "  'emborracho#': 562,\n",
              "  'empeorando#': 563,\n",
              "  'convencida#': 564,\n",
              "  'convencido#': 565,\n",
              "  'conspiraci#': 566,\n",
              "  'emergencia#': 567,\n",
              "  'escucharme#': 568,\n",
              "  'terminemos#': 569,\n",
              "  'escondamos#': 570,\n",
              "  'explicarte#': 571,\n",
              "  'perdonarme#': 572,\n",
              "  'molestarme#': 573,\n",
              "  'firmemente#': 574,\n",
              "  'desafilado#': 575,\n",
              "  'agonizando#': 576,\n",
              "  'continuaba#': 577,\n",
              "  'verdaderos#': 578,\n",
              "  'ablemente#': 579,\n",
              "  'desperdici': 580,\n",
              "  'entemente#': 581,\n",
              "  'intercambi': 582,\n",
              "  'interrumpi': 583,\n",
              "  'extraordin': 584,\n",
              "  'menospreci': 585,\n",
              "  'contradeci': 586,\n",
              "  'sualmente#': 587,\n",
              "  'agradable#': 588,\n",
              "  'terminado#': 589,\n",
              "  'americano#': 590,\n",
              "  'contentos#': 591,\n",
              "  'conocimos#': 592,\n",
              "  'necesario#': 593,\n",
              "  'tranquiliz': 594,\n",
              "  'confirmar#': 595,\n",
              "  'accionado#': 596,\n",
              "  'ticamente#': 597,\n",
              "  'tivamente#': 598,\n",
              "  'perfeccion': 599,\n",
              "  'aceptable#': 600,\n",
              "  'hermanastr': 601,\n",
              "  'alentador#': 602,\n",
              "  'apropiado#': 603,\n",
              "  'entendido#': 604,\n",
              "  'ariamente#': 605,\n",
              "  'nicamente#': 606,\n",
              "  'torreando#': 607,\n",
              "  'distinguir': 608,\n",
              "  'reconsider': 609,\n",
              "  'versibles#': 610,\n",
              "  'ciplinado#': 611,\n",
              "  'enorgullec': 612,\n",
              "  'levantado#': 613,\n",
              "  'imposible#': 614,\n",
              "  'tranquilo#': 615,\n",
              "  'despierta#': 616,\n",
              "  'encuentre#': 617,\n",
              "  'calentito#': 618,\n",
              "  'divertido#': 619,\n",
              "  'prohibido#': 620,\n",
              "  'demasiado#': 621,\n",
              "  'preguntes#': 622,\n",
              "  'preparaos#': 623,\n",
              "  'despierto#': 624,\n",
              "  'televisor#': 625,\n",
              "  'rdenselos#': 626,\n",
              "  'mantenete#': 627,\n",
              "  'prendedlo#': 628,\n",
              "  'marcharon#': 629,\n",
              "  'perdieron#': 630,\n",
              "  'olvidamos#': 631,\n",
              "  'esperamos#': 632,\n",
              "  'dieciocho#': 633,\n",
              "  'cuidadoso#': 634,\n",
              "  'acercarme#': 635,\n",
              "  'comprobad#': 636,\n",
              "  'comprueba#': 637,\n",
              "  'arruinado#': 638,\n",
              "  'mintiendo#': 639,\n",
              "  'corriendo#': 640,\n",
              "  'ejercicio#': 641,\n",
              "  'mentiroso#': 642,\n",
              "  'comprando#': 643,\n",
              "  'codicioso#': 644,\n",
              "  'escondido#': 645,\n",
              "  'estupendo#': 646,\n",
              "  'grandioso#': 647,\n",
              "  'charlemos#': 648,\n",
              "  'caminemos#': 649,\n",
              "  'problemas#': 650,\n",
              "  'retrocede#': 651,\n",
              "  'pertenece#': 652,\n",
              "  'disparado#': 653,\n",
              "  'compramos#': 654,\n",
              "  'echaremos#': 655,\n",
              "  'regresado#': 656,\n",
              "  'marcharte#': 657,\n",
              "  'marcharos#': 658,\n",
              "  'marcharse#': 659,\n",
              "  'creativos#': 660,\n",
              "  'preparado#': 661,\n",
              "  'puntuales#': 662,\n",
              "  'razonable#': 663,\n",
              "  'tolerante#': 664,\n",
              "  'vigilante#': 665,\n",
              "  'conversar#': 666,\n",
              "  'preocupes#': 667,\n",
              "  'encontrar#': 668,\n",
              "  'asqueroso#': 669,\n",
              "  'fingiendo#': 670,\n",
              "  'encuentro#': 671,\n",
              "  'compartir#': 672,\n",
              "  'impuestos#': 673,\n",
              "  'agradezco#': 674,\n",
              "  'despedido#': 675,\n",
              "  'preguntar#': 676,\n",
              "  'perdedora#': 677,\n",
              "  'cocinando#': 678,\n",
              "  'saludable#': 679,\n",
              "  'enamorada#': 680,\n",
              "  'esperando#': 681,\n",
              "  'ignoralos#': 682,\n",
              "  'encuentra#': 683,\n",
              "  'normativa#': 684,\n",
              "  'fresquito#': 685,\n",
              "  'empecemos#': 686,\n",
              "  'caballero#': 687,\n",
              "  'significa#': 688,\n",
              "  'responded#': 689,\n",
              "  'descansad#': 690,\n",
              "  'abrazaron#': 691,\n",
              "  'sonrieron#': 692,\n",
              "  'esperaron#': 693,\n",
              "  'caminaron#': 694,\n",
              "  'separamos#': 695,\n",
              "  'conocemos#': 696,\n",
              "  'acordamos#': 697,\n",
              "  'estaremos#': 698,\n",
              "  'hicisteis#': 699,\n",
              "  'necesitas#': 700,\n",
              "  'retrasado#': 701,\n",
              "  'abandonen#': 702,\n",
              "  'confianza#': 703,\n",
              "  'seguridad#': 704,\n",
              "  'objetivos#': 705,\n",
              "  'paciencia#': 706,\n",
              "  'enseguida#': 707,\n",
              "  'fantasmas#': 708,\n",
              "  'rosquilla#': 709,\n",
              "  'valientes#': 710,\n",
              "  'humillado#': 711,\n",
              "  'prestigio#': 712,\n",
              "  'sufriendo#': 713,\n",
              "  'arrogante#': 714,\n",
              "  'lesionado#': 715,\n",
              "  'atracaron#': 716,\n",
              "  'simpatizo#': 717,\n",
              "  'enmarcado#': 718,\n",
              "  'arriesgar#': 719,\n",
              "  'congelado#': 720,\n",
              "  'vacilante#': 721,\n",
              "  'preparada#': 722,\n",
              "  'durmiendo#': 723,\n",
              "  'meditando#': 724,\n",
              "  'reventado#': 725,\n",
              "  'sonriendo#': 726,\n",
              "  'continuad#': 727,\n",
              "  'caminando#': 728,\n",
              "  'tranquila#': 729,\n",
              "  'permanece#': 730,\n",
              "  'funcionar#': 731,\n",
              "  'escaparon#': 732,\n",
              "  'rindieron#': 733,\n",
              "  'necesitan#': 734,\n",
              "  'muchachos#': 735,\n",
              "  'encuerado#': 736,\n",
              "  'sobrevivi#': 737,\n",
              "  'centrarte#': 738,\n",
              "  'disculpas#': 739,\n",
              "  'saldremos#': 740,\n",
              "  'asustados#': 741,\n",
              "  'bromeando#': 742,\n",
              "  'perdiendo#': 743,\n",
              "  'cambiamos#': 744,\n",
              "  'consegido#': 745,\n",
              "  'diviertes#': 746,\n",
              "  'descansar#': 747,\n",
              "  'acalorado#': 748,\n",
              "  'acalorada#': 749,\n",
              "  'despedida#': 750,\n",
              "  'ingenioso#': 751,\n",
              "  'ocurrente#': 752,\n",
              "  'intentado#': 753,\n",
              "  'siguiente#': 754,\n",
              "  'abrazarte#': 755,\n",
              "  'pidamente#': 756,\n",
              "  'presiones#': 757,\n",
              "  'apresures#': 758,\n",
              "  'preparame#': 759,\n",
              "  'apedreado#': 760,\n",
              "  'indignado#': 761,\n",
              "  'desprecio#': 762,\n",
              "  'resfriado#': 763,\n",
              "  'repararlo#': 764,\n",
              "  'tripulaci#': 765,\n",
              "  'desarmado#': 766,\n",
              "  'observaba#': 767,\n",
              "  'demostrar#': 768,\n",
              "  'imparcial#': 769,\n",
              "  'intrigada#': 770,\n",
              "  'asegurado#': 771,\n",
              "  'asegurada#': 772,\n",
              "  'lloviendo#': 773,\n",
              "  'avancemos#': 774,\n",
              "  'atendedme#': 775,\n",
              "  'arreglalo#': 776,\n",
              "  'continuar#': 777,\n",
              "  'calladito#': 778,\n",
              "  'comiencen#': 779,\n",
              "  'manteneos#': 780,\n",
              "  'partieron#': 781,\n",
              "  'encantaba#': 782,\n",
              "  'borrachos#': 783,\n",
              "  'pacientes#': 784,\n",
              "  'hundiendo#': 785,\n",
              "  'concluido#': 786,\n",
              "  'atrapados#': 787,\n",
              "  'equivocan#': 788,\n",
              "  'preguntas#': 789,\n",
              "  'proseguir#': 790,\n",
              "  'olvidaste#': 791,\n",
              "  'forcejees#': 792,\n",
              "  'disfruten#': 793,\n",
              "  'disfrutad#': 794,\n",
              "  'cambiarte#': 795,\n",
              "  'deprimido#': 796,\n",
              "  'conducido#': 797,\n",
              "  'nostalgia#': 798,\n",
              "  'garantizo#': 799,\n",
              "  'acertijos#': 800,\n",
              "  'espinacas#': 801,\n",
              "  'escuincle#': 802,\n",
              "  'equivoque#': 803,\n",
              "  'bocadillo#': 804,\n",
              "  'estornudo#': 805,\n",
              "  'renunciar#': 806,\n",
              "  'arrestado#': 807,\n",
              "  'arrestada#': 808,\n",
              "  'capturado#': 809,\n",
              "  'prosperar#': 810,\n",
              "  'asombrada#': 811,\n",
              "  'cansancio#': 812,\n",
              "  'confiable#': 813,\n",
              "  'devastada#': 814,\n",
              "  'fascinada#': 815,\n",
              "  'sintiendo#': 816,\n",
              "  'optimista#': 817,\n",
              "  'lastimado#': 818,\n",
              "  'delicioso#': 819,\n",
              "  'diferente#': 820,\n",
              "  'demasiada#': 821,\n",
              "  'esperemos#': 822,\n",
              "  'trampilla#': 823,\n",
              "  'empezamos#': 824,\n",
              "  'estrangul#': 825,\n",
              "  'bicicleta#': 826,\n",
              "  'enfermera#': 827,\n",
              "  'provocaba#': 828,\n",
              "  'testaruda#': 829,\n",
              "  'primavera#': 830,\n",
              "  'volvieron#': 831,\n",
              "  'quisieron#': 832,\n",
              "  'responder#': 833,\n",
              "  'intervino#': 834,\n",
              "  'servicial#': 835,\n",
              "  'enamorado#': 836,\n",
              "  'temblando#': 837,\n",
              "  'malcriado#': 838,\n",
              "  'retratado#': 839,\n",
              "  'adoptamos#': 840,\n",
              "  'apuntamos#': 841,\n",
              "  'esperanza#': 842,\n",
              "  'inquietos#': 843,\n",
              "  'cambiaste#': 844,\n",
              "  'ignorabas#': 845,\n",
              "  'ignoraste#': 846,\n",
              "  'cualquier#': 847,\n",
              "  'comprarme#': 848,\n",
              "  'ayudarnos#': 849,\n",
              "  'mostrarme#': 850,\n",
              "  'escotilla#': 851,\n",
              "  'ahoritita#': 852,\n",
              "  'recuerdas#': 853,\n",
              "  'recuerdes#': 854,\n",
              "  'aproveche#': 855,\n",
              "  'alcanzame#': 856,\n",
              "  'tendencia#': 857,\n",
              "  'jardinero#': 858,\n",
              "  'realmente#': 859,\n",
              "  'muchachas#': 860,\n",
              "  'impotente#': 861,\n",
              "  'indefenso#': 862,\n",
              "  'rechazado#': 863,\n",
              "  'lapiceras#': 864,\n",
              "  'pastillas#': 865,\n",
              "  'afeitarme#': 866,\n",
              "  'reconozco#': 867,\n",
              "  'comprendo#': 868,\n",
              "  'profesora#': 869,\n",
              "  'extenuado#': 870,\n",
              "  'sorprendi#': 871,\n",
              "  'cristiano#': 872,\n",
              "  'detective#': 873,\n",
              "  'ingeniero#': 874,\n",
              "  'peligroso#': 875,\n",
              "  'sofocante#': 876,\n",
              "  'solamente#': 877,\n",
              "  'emborrach#': 878,\n",
              "  'colectivo#': 879,\n",
              "  'visitemos#': 880,\n",
              "  'encendida#': 881,\n",
              "  'charlaron#': 882,\n",
              "  'amarillos#': 883,\n",
              "  'amarillas#': 884,\n",
              "  'saludaron#': 885,\n",
              "  'ignoraron#': 886,\n",
              "  'separados#': 887,\n",
              "  'contentas#': 888,\n",
              "  'correctos#': 889,\n",
              "  'nerviosos#': 890,\n",
              "  'charlando#': 891,\n",
              "  'sangrando#': 892,\n",
              "  'insolente#': 893,\n",
              "  'inspirado#': 894,\n",
              "  'implicado#': 895,\n",
              "  'enfermero#': 896,\n",
              "  'impactado#': 897,\n",
              "  'averiguar#': 898,\n",
              "  'ayudarlos#': 899,\n",
              "  'cordiales#': 900,\n",
              "  'respuesta#': 901,\n",
              "  'descubrir#': 902,\n",
              "  'agradecer#': 903,\n",
              "  'inocentes#': 904,\n",
              "  'estancado#': 905,\n",
              "  'japoneses#': 906,\n",
              "  'quedarnos#': 907,\n",
              "  'verifique#': 908,\n",
              "  'persianas#': 909,\n",
              "  'descansas#': 910,\n",
              "  'sermonees#': 911,\n",
              "  'desanimes#': 912,\n",
              "  'menciones#': 913,\n",
              "  'escaleras#': 914,\n",
              "  'decidiste#': 915,\n",
              "  'fascinaba#': 916,\n",
              "  'padrastro#': 917,\n",
              "  'sobrepeso#': 918,\n",
              "  'permaneci#': 919,\n",
              "  'solitario#': 920,\n",
              "  'momentito#': 921,\n",
              "  'aborrezco#': 922,\n",
              "  'violencia#': 923,\n",
              "  'mostrarte#': 924,\n",
              "  'detenerla#': 925,\n",
              "  'simpatiza#': 926,\n",
              "  'relajarme#': 927,\n",
              "  'sorpresas#': 928,\n",
              "  'conseguir#': 929,\n",
              "  'australia#': 930,\n",
              "  'asombrado#': 931,\n",
              "  'comprobar#': 932,\n",
              "  'consultar#': 933,\n",
              "  'ciudadano#': 934,\n",
              "  'ciudadana#': 935,\n",
              "  'traductor#': 936,\n",
              "  'dispuesto#': 937,\n",
              "  'colaborar#': 938,\n",
              "  'invitando#': 939,\n",
              "  'orgulloso#': 940,\n",
              "  'orgullosa#': 941,\n",
              "  'ahorrando#': 942,\n",
              "  'contactar#': 943,\n",
              "  'enchinada#': 944,\n",
              "  'emboscada#': 945,\n",
              "  'aterrador#': 946,\n",
              "  'temporada#': 947,\n",
              "  'izquierda#': 948,\n",
              "  'informado#': 949,\n",
              "  'manteneme#': 950,\n",
              "  'barrilete#': 951,\n",
              "  'pesquemos#': 952,\n",
              "  'rescatate#': 953,\n",
              "  'retroceda#': 954,\n",
              "  'oraciones#': 955,\n",
              "  'desprecia#': 956,\n",
              "  'promovida#': 957,\n",
              "  'mostranos#': 958,\n",
              "  'asombroso#': 959,\n",
              "  'mejorable#': 960,\n",
              "  'mejorarse#': 961,\n",
              "  'carretera#': 962,\n",
              "  'congelada#': 963,\n",
              "  'despejado#': 964,\n",
              "  'cantantes#': 965,\n",
              "  'mintieron#': 966,\n",
              "  'confiaron#': 967,\n",
              "  'confiaban#': 968,\n",
              "  'inmaduros#': 969,\n",
              "  'traidores#': 970,\n",
              "  'relajante#': 971,\n",
              "  'rehusarse#': 972,\n",
              "  'campesino#': 973,\n",
              "  'refugiado#': 974,\n",
              "  'camionero#': 975,\n",
              "  'ambicioso#': 976,\n",
              "  'brillante#': 977,\n",
              "  'volviendo#': 978,\n",
              "  'emocional#': 979,\n",
              "  'mejorando#': 980,\n",
              "  'ocultando#': 981,\n",
              "  'ejecutado#': 982,\n",
              "  'torturado#': 983,\n",
              "  'trabajaba#': 984,\n",
              "  'desprenda#': 985,\n",
              "  'aceptamos#': 986,\n",
              "  'confiamos#': 987,\n",
              "  'referimos#': 988,\n",
              "  'sentarnos#': 989,\n",
              "  'pagaremos#': 990,\n",
              "  'dijisteis#': 991,\n",
              "  'desgracia#': 992,\n",
              "  'golpearon#': 993,\n",
              "  'atrasaste#': 994,\n",
              "  'estuviste#': 995,\n",
              "  'necesitar#': 996,\n",
              "  'motivados#': 997,\n",
              "  'engordado#': 998,\n",
              "  'compraste#': 999,\n",
              "  'comprende#': 1000,\n",
              "  'defraudes#': 1001,\n",
              "  'temerario#': 1002,\n",
              "  'verdadero#': 1003,\n",
              "  ...})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentence = english_sentence[:20000]\n",
        "spanish_sentence = spanish_sentence[:20000]"
      ],
      "metadata": {
        "id": "uB3upyat7Or-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(english_sentence),len(spanish_sentence)"
      ],
      "metadata": {
        "id": "7hNF0kdQ5zGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95fe01d0-f98a-4156-bc66-512f9c02df2e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 20000)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0gpYOyFkQFy",
        "outputId": "c6c78dd1-5336-45c7-a227-b89db042edb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['go', 'go', 'go', 'go', 'hi', 'run', 'run', 'who', 'fire', 'fire']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "english_sentence[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dv7VWb8GkWHh",
        "outputId": "ba8f6953-3a2a-46f6-89e8-9a342ff8b724"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ve',\n",
              " 'vete',\n",
              " 'vaya',\n",
              " 'v yase',\n",
              " 'hola',\n",
              " 'corre',\n",
              " 'corred',\n",
              " 'qui n',\n",
              " 'fuego',\n",
              " 'incendio']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "spanish_sentence[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYljiEZkkiA0",
        "outputId": "9abc2458-63fc-45db-d38f-8a3c88629128"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19, 66)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "max(len(x) for x in english_sentence),max(len(x) for x in spanish_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1g1mTQwkwt6",
        "outputId": "1de9af76-0405-4d82-bba0-2258e1a2c9dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14.9992\n",
            "16.39655\n"
          ]
        }
      ],
      "source": [
        "# computing avg length\n",
        "print(sum(len(x) for x in english_sentence)/len(english_sentence))\n",
        "print(sum(len(x) for x in spanish_sentence)/len(spanish_sentence))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "vtca6awt9J_z"
      },
      "outputs": [],
      "source": [
        "d_model = 152\n",
        "batch_size = 16\n",
        "ffn_hidden = 152\n",
        "num_heads = 2\n",
        "drop_prob = 0.1\n",
        "num_stacked = 1\n",
        "max_token_length = 7\n",
        "sp_vocab_size = len(sp_lng_to_index)\n",
        "en_vocab_size = len(en_lng_to_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkbD6SsvsbYv"
      },
      "source": [
        "limit the length of the sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhCxoQqzq4o3",
        "outputId": "bd7a5a0f-f670-46f3-8f76-42d40853c56b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19, 66)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "max(len(x) for x in english_sentence),max(len(x) for x in spanish_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "O5am0HOPuWHz"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "  '''\n",
        "  overriding certain methods of the Dataset class\n",
        "  '''\n",
        "  def __init__(self,english_sentence,spanish_sentence):\n",
        "    self.english_sentence = english_sentence\n",
        "    self.spanish_sentence = spanish_sentence\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.english_sentence)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.english_sentence[index],self.spanish_sentence[index]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Y0q7IGjZvVEH"
      },
      "outputs": [],
      "source": [
        "dataset = TextDataset(english_sentence,spanish_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eI5iOYbvX77",
        "outputId": "9aa06219-384e-4fc6-9b27-2456cf982bad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "KRLIKa_tv_CJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_loader = DataLoader(dataset,batch_size=batch_size)\n",
        "iterator = iter(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBTgtR9cwUSA",
        "outputId": "e4d9af25-f902-4b07-cbdb-676766e1a554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('go', 'go', 'go', 'go', 'hi', 'run', 'run', 'who', 'fire', 'fire', 'fire', 'help', 'help', 'help', 'jump', 'jump'), ('ve', 'vete', 'vaya', 'v yase', 'hola', 'corre', 'corred', 'qui n', 'fuego', 'incendio', 'disparad', 'ayuda', 'socorro auxilio', 'auxilio', 'salta', 'salte')]\n",
            "[('stop', 'stop', 'stop', 'wait', 'wait', 'go on', 'go on', 'hello', 'i ran', 'i ran', 'i try', 'i won', 'oh no', 'relax', 'smile', 'attack'), ('parad', 'para', 'pare', 'espera', 'esperen', 'contin a', 'contin e', 'hola', 'corr', 'corr a', 'lo intento', 'he ganado', 'oh no', 'tom telo con soda', 'sonr e', 'al ataque')]\n",
            "[('attack', 'get up', 'go now', 'got it', 'got it', 'got it', 'he ran', 'hop in', 'hug me', 'i fell', 'i know', 'i left', 'i lied', 'i lost', 'i quit', 'i quit'), ('atacad', 'levanta', 've ahora mismo', 'lo tengo', 'lo pillas', 'entendiste', 'l corri', 'm tete adentro', 'abr zame', 'me ca', 'yo lo s', 'sal', 'ment', 'perd', 'dimito', 'renunci')]\n",
            "[('i work', 'i m', 'i m up', 'listen', 'listen', 'listen', 'no way', 'no way', 'no way', 'no way', 'no way', 'no way', 'no way', 'no way', 'no way', 'no way'), ('estoy trabajando', 'tengo diecinueve', 'estoy levantado', 'escucha', 'escuche', 'escuchen', 'no puede ser', 'de ninguna manera', 'de ninguna manera', 'imposible', 'de ning n modo', 'de eso nada', 'ni cagando', 'mangos', 'minga', 'ni en pedo')]\n",
            "[('really', 'really', 'thanks', 'thanks', 'try it', 'we try', 'we won', 'why me', 'ask tom', 'awesome', 'be calm', 'be cool', 'be fair', 'be kind', 'be nice', 'beat it'), ('en serio', 'la verdad', 'gracias', 'gracias', 'pru balo', 'lo procuramos', 'ganamos', 'por qu yo', 'preg ntale a tom', 'rale', 'mantente en calma', 'estate tranquilo', 's justo', 'sean gentiles', 's agradable', 'p rate')]\n"
          ]
        }
      ],
      "source": [
        "for batch_num,batch in enumerate(iterator):\n",
        "  print(batch)\n",
        "  # break\n",
        "  if (batch_num > 3):\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "eVHzNQWAA8g2"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(d_model,\n",
        "                          ffn_hidden,\n",
        "                          num_heads,\n",
        "                          drop_prob,\n",
        "                          num_stacked,\n",
        "                          max_token_length,\n",
        "                          sp_vocab_size,\n",
        "                          en_lng_to_index,\n",
        "                          sp_lng_to_index,\n",
        "                          START_TOKEN,\n",
        "                          END_TOKEN,\n",
        "                          PADDING_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkQmg8k5DCXh",
        "outputId": "14ed3785-470a-45c6-f92d-9b44fe2bf251"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (sentence_embedding): SentenceEmbedding(\n",
              "      (embedding): Embedding(7326, 152)\n",
              "      (position_encoder): AbsolutePositionalEncoding()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): SequentialEncoder(\n",
              "      (0): EncoderLayer(\n",
              "        (attention): MultiHeadAttention(\n",
              "          (qkv_layer): Linear(in_features=152, out_features=456, bias=True)\n",
              "          (linear_layer): Linear(in_features=152, out_features=152, bias=True)\n",
              "        )\n",
              "        (norm1): LayerNormalization()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (ffn): PositionalwiseFeedForwrd(\n",
              "          (linear1): Linear(in_features=152, out_features=152, bias=True)\n",
              "          (linear2): Linear(in_features=152, out_features=152, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (norm2): LayerNormalization()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (sentence_embedding): SentenceEmbedding(\n",
              "      (embedding): Embedding(8358, 152)\n",
              "      (position_encoder): AbsolutePositionalEncoding()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): SequentialDecoder(\n",
              "      (0): DecoderLayer(\n",
              "        (masked_attention): MultiHeadAttention(\n",
              "          (qkv_layer): Linear(in_features=152, out_features=456, bias=True)\n",
              "          (linear_layer): Linear(in_features=152, out_features=152, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (norm1): LayerNormalization()\n",
              "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
              "          (kv_layer): Linear(in_features=152, out_features=304, bias=True)\n",
              "          (q_layer): Linear(in_features=152, out_features=152, bias=True)\n",
              "          (linear_layer): Linear(in_features=152, out_features=152, bias=True)\n",
              "        )\n",
              "        (norm2): LayerNormalization()\n",
              "        (ffn): PositionalwiseFeedForwrd(\n",
              "          (linear1): Linear(in_features=152, out_features=152, bias=True)\n",
              "          (linear2): Linear(in_features=152, out_features=152, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (norm3): LayerNormalization()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=152, out_features=8358, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "meuR2adX-h8y"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "criterian = nn.CrossEntropyLoss(ignore_index=sp_lng_to_index[PADDING_TOKEN],\n",
        "                                reduction='none')\n",
        "\n",
        "# When computing the loss, we are ignoring cases when the label is the padding token\n",
        "for params in transformer.parameters():\n",
        "    if params.dim() > 1:\n",
        "        nn.init.xavier_uniform_(params)\n",
        "\n",
        "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
        "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "GTV2rZfRDk15"
      },
      "outputs": [],
      "source": [
        "NEG_INFTY = -1e9\n",
        "\n",
        "def create_masks(eng_batch, sp_batch):\n",
        "    num_sentences = len(eng_batch) # {represent batch size}\n",
        "    look_ahead_mask = torch.full([max_token_length, max_token_length] , True)\n",
        "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
        "    encoder_padding_mask = torch.full([num_sentences, max_token_length, max_token_length] , False)\n",
        "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_token_length, max_token_length] , False)\n",
        "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_token_length, max_token_length] , False)\n",
        "\n",
        "    for idx in range(num_sentences):\n",
        "      eng_sentence_length, sp_sentence_length = len(eng_batch[idx]), len(sp_batch[idx])\n",
        "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_token_length)\n",
        "      sp_chars_to_padding_mask = np.arange(sp_sentence_length + 1, max_token_length)\n",
        "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
        "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_self_attention[idx, :, sp_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_self_attention[idx, sp_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_cross_attention[idx, sp_chars_to_padding_mask, :] = True\n",
        "\n",
        "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
        "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
        "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
        "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8kyA6OsJWKA"
      },
      "source": [
        "Explaination 1 :\n",
        "\n",
        "encoder_self_attention_mask and decoder_cross_attention_mask are used so that transformer do not pay attention to the padding tokens (which is done by putting zeros (till the length of the sentence + 1) and remaning part in sequence is covered by -infinity)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        example:\n",
        "        max_sequence_length  = 8,   \n",
        "                  sentence =  'good'(len = 4),num_sentence = 1\n",
        "                  zero values should be till index len(sentence) + 1\n",
        "\n",
        "\n",
        "        mask = [[[0 0 0 0 0 -inf -inf -inf],\n",
        "                 [0 0 0 0 0 -inf -inf -inf],\n",
        "                 [0 0 0 0 0 -inf -inf -inf],\n",
        "                 [0 0 0 0 0 -inf -inf -inf],\n",
        "                 [0 0 0 0 0 -inf -inf -inf],\n",
        "                 [0 0 0 0 0 -inf -inf -inf],\n",
        "                 [0 0 0 0 0 -inf -inf -inf],\n",
        "                 [0 0 0 0 0 -inf -inf -inf]]]\n",
        "                shape (num_sentence,max_sequence_length,max_sequence_length)\n",
        "        \n",
        "        attention_weights = [[[0.00426842, 0.00752416, 0.00349225, 0.00898395, 0.00556792, -0.00568639, -0.00325177, 0.00724002],\n",
        "                             [0.00921758, 0.00367077, 0.00327958, 0.00263405, 0.00764168, -0.00392446, -0.00628386, 0.00685052],\n",
        "                             [0.00997227, 0.00228168, 0.00833329, 0.00146394, 0.00922879, -0.00393896, -0.00372312, 0.00919514],\n",
        "                             [0.00588389, 0.00815015, 0.00625498, 0.00393098, 0.0071409, -0.00682445, -0.00449244, 0.00170309],\n",
        "                             [0.00125849, 0.00692958, 0.00917532, 0.00639848, 0.00209307, -0.00023777, -0.00540265, 0.00118428],\n",
        "                             [0.00485591, 0.00195363, 0.00936389, 0.00918742, 0.00358588, -0.00993245, -0.00042846, 0.00660049],\n",
        "                             [0.00730663, 0.00275739, 0.00828811, 0.00286777, 0.00250849, -0.00248524, -0.00326519, 0.00197197],\n",
        "                             [0.00901291, 0.00702945, 0.00767226, 0.00873171, 0.0090118, -0.00064111, -0.00999714, 0.00365651]]]\n",
        "                             shape (batch_size = 1,max_sequence_length,max_sequence_length)\n",
        "\n",
        "\n",
        "        result =  (mask + attention_weights)\n",
        "                         [[[0.00426842, 0.00752416, 0.00349225, 0.00898395, 0.00556792, -inf, -inf, -inf],\n",
        "                         [0.00921758, 0.00367077, 0.00327958, 0.00263405, 0.00764168, -inf, -inf, -inf],\n",
        "                         [0.00997227, 0.00228168, 0.00833329, 0.00146394, 0.00922879, -inf, -inf, -inf],\n",
        "                         [0.00588389, 0.00815015, 0.00625498, 0.00393098, 0.0071409, -inf, -inf,-inf],\n",
        "                         [0.00125849, 0.00692958, 0.00917532, 0.00639848, 0.00209307, -inf, -inf, -inf],\n",
        "                         [0.00485591, 0.00195363, 0.00936389, 0.00918742, 0.00358588, -inf, -inf,-inf],\n",
        "                         [0.00730663, 0.00275739, 0.00828811, 0.00286777, 0.00250849, -inf, -inf, -inf],\n",
        "                         [0.00901291, 0.00702945, 0.00767226, 0.00873171, 0.0090118, -inf, -inf, -inf]]]\n",
        "            \n",
        "\n",
        "\n",
        "        softmax(result,dim = -1)\n",
        "                  [[[0.1997, 0.2003, 0.1995, 0.2006, 0.1999, 0.0000, 0.0000, 0.0000],\n",
        "                    [0.2008, 0.1997, 0.1996, 0.1995, 0.2005, 0.0000, 0.0000, 0.0000],\n",
        "                    [0.2007, 0.1992, 0.2004, 0.1990, 0.2006, 0.0000, 0.0000, 0.0000],\n",
        "                    [0.1999, 0.2004, 0.2000, 0.1995, 0.2002, 0.0000, 0.0000, 0.0000],\n",
        "                    [0.1992, 0.2004, 0.2008, 0.2002, 0.1994, 0.0000, 0.0000, 0.0000],\n",
        "                    [0.1998, 0.1992, 0.2007, 0.2007, 0.1996, 0.0000, 0.0000, 0.0000],\n",
        "                    [0.2005, 0.1996, 0.2007, 0.1996, 0.1996, 0.0000, 0.0000, 0.0000],\n",
        "                    [0.2001, 0.1997, 0.1999, 0.2001, 0.2001, 0.0000, 0.0000, 0.0000]]]\n",
        "\n",
        "                         \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Explaination 2 :\n",
        "\n",
        "decoder_self_attention_mask is mainly used by the decoder's first sublayer known as masked_self_attention which is used so that while producing target token ,decoder should not able to see(or attend)  the future token or words\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      example:\n",
        "        max_sequence_length  = 8,   \n",
        "                  sentence =  'good'(len = 4),num_sentence = 1\n",
        "                  zero values should be till index len(sentence) + 1\n",
        "\n",
        "\n",
        "        mask = [[[0 -inf -inf -inf -inf -inf -inf -inf],\n",
        "                 [0  0  -inf  -inf -inf -inf -inf -inf],\n",
        "                 [0  0   0   -inf  -inf -inf -inf -inf],\n",
        "                 [0  0   0   0  -inf -inf -inf -inf],\n",
        "                 [0  0   0   0   0 -inf -inf -inf],\n",
        "                 [-inf -inf -inf -inf -inf  -inf -inf -inf],\n",
        "                 [-inf -inf -inf -inf -inf -inf -inf -inf],\n",
        "                 [-inf -inf -inf -inf -inf -inf -inf -inf ]]\n",
        "                shape (num_sentence,max_sequence_length,max_sequence_length)\n",
        "\n",
        "\n",
        "                Last  few vectors are filled  with infinity values\n",
        "                because zeros have filled the total index which they can fill\n",
        "                that is (len(good) + 1) and after that all is padding token where we do not need to pay attention that's why after paying attention to the last token of the sequence ,the next rows are filled with -infinity\n",
        "\n",
        "                & Similar above steps..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn6vcch0F9gu",
        "outputId": "d6cad8bd-095c-4c42-f22d-8237ca681b7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "eng_batch = (\"happy\",'good','joyful','sri ram jai ram')\n",
        "sp_batch = (\"happy\",'good','joyful','hbhwsd')\n",
        "\n",
        "encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch,sp_batch)\n",
        "encoder_self_attention_mask.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6mxDm4iGzW5",
        "outputId": "2e6bffee-633e-4a7d-da63-3b3a60fc13fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00, -1.0000e+09],\n",
              "        [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "encoder_self_attention_mask[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCZNSw677ERg",
        "outputId": "646f4e1f-a8f8-4d25-f672-96a5528f19f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00, -1.0000e+09],\n",
              "        [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "decoder_self_attention_mask[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD8i3sis7Nck",
        "outputId": "fa2b6f91-56de-49c0-d93d-c5db9357eea4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00, -1.0000e+09],\n",
              "        [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "decoder_cross_attention_mask[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HHcp31W_wNp",
        "outputId": "59818b3d-fde3-41d3-9357-1bea29c68694"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "decoder_self_attention_mask[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(en_index_to_lng)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH24LbAc0_Dl",
        "outputId": "02a04128-3eb7-406a-f2cf-13e87a698806"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7326"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwdwXFz4CYFZ",
        "outputId": "197008ea-6940-4d3c-c2fd-0c0b9e16b142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 batch 0 loss 8.971413612365723\n",
            "English: go\n",
            "Spanish Translation: ve\n",
            "Spaniish Prediction: asfixi#cirug#eguarruinadas#despu#omeespesa#\n",
            "Evaluation translation of everyone is happy : cirug#cirug#empeora#amenhabithabithabit\n",
            "-----------------------------------------------------------\n",
            "epoch 0 batch 100 loss 7.5302581787109375\n",
            "English: be sensible\n",
            "Spanish Translation: sed razonables\n",
            "Spaniish Prediction: \n",
            "Evaluation translation of everyone is happy : <END>\n",
            "-----------------------------------------------------------\n",
            "epoch 0 batch 200 loss 6.425028324127197\n",
            "English: she stood up\n",
            "Spanish Translation: ella se levant\n",
            "Spaniish Prediction: \n",
            "Evaluation translation of everyone is happy : <END>\n",
            "-----------------------------------------------------------\n",
            "epoch 0 batch 300 loss 6.201528549194336\n",
            "English: life is tough\n",
            "Spanish Translation: la vida es dura\n",
            "Spaniish Prediction: \n",
            "Evaluation translation of everyone is happy : <END>\n",
            "-----------------------------------------------------------\n",
            "epoch 0 batch 400 loss 5.417425632476807\n",
            "English: it s tom s job\n",
            "Spanish Translation: es la tarea de tom\n",
            "Spaniish Prediction: \n",
            "Evaluation translation of everyone is happy : <END>\n",
            "-----------------------------------------------------------\n",
            "epoch 0 batch 500 loss 5.9063239097595215\n",
            "English: i have an apple\n",
            "Spanish Translation: tengo una manzana\n",
            "Spaniish Prediction: \n",
            "Evaluation translation of everyone is happy : <END>\n",
            "-----------------------------------------------------------\n",
            "epoch 0 batch 600 loss 5.415184497833252\n",
            "English: why are you sad\n",
            "Spanish Translation: por qu est s triste\n",
            "Spaniish Prediction: \n",
            "Evaluation translation of everyone is happy : <END>\n",
            "-----------------------------------------------------------\n",
            "epoch 0 batch 700 loss 6.326675891876221\n",
            "English: let me try again\n",
            "Spanish Translation: d jame tratar otra vez\n",
            "Spaniish Prediction: \n",
            "Evaluation translation of everyone is happy : <END>\n",
            "-----------------------------------------------------------\n",
            "epoch 0 batch 800 loss 5.8426079750061035\n",
            "English: did you know that\n",
            "Spanish Translation: sab as eso\n",
            "Spaniish Prediction: tom#es#es#\n",
            "Evaluation translation of everyone is happy : es#es#<END>\n",
            "-----------------------------------------------------------\n",
            "epoch 0 batch 900 loss 5.104892730712891\n",
            "English: thanks in advance\n",
            "Spanish Translation: gracias en avance\n",
            "Spaniish Prediction: es#no#a#\n",
            "Evaluation translation of everyone is happy : es#es#<END>\n",
            "-----------------------------------------------------------\n",
            "epoch 0 batch 1000 loss 5.440508842468262\n",
            "English: he changed his job\n",
            "Spanish Translation: l cambi de empleo\n",
            "Spaniish Prediction: es#es#tom#\n",
            "Evaluation translation of everyone is happy : es#es#<END>\n",
            "-----------------------------------------------------------\n",
            "epoch 0 batch 1100 loss 6.178808212280273\n",
            "English: stop that tickles\n",
            "Spanish Translation: para hace cosquillas\n",
            "Spaniish Prediction: es#es#a#a#\n",
            "Evaluation translation of everyone is happy : a#a#<END>\n",
            "-----------------------------------------------------------\n",
            "epoch 0 batch 1200 loss 6.112847328186035\n",
            "English: can he speak french\n",
            "Spanish Translation: l habla franc s\n",
            "Spaniish Prediction: tom#tom#es#\n",
            "Evaluation translation of everyone is happy : tom#tom#<END>\n",
            "-----------------------------------------------------------\n",
            "epoch 1 batch 0 loss 6.862048625946045\n",
            "English: go\n",
            "Spanish Translation: ve\n",
            "Spaniish Prediction: no#a#\n",
            "Evaluation translation of everyone is happy : a#a#<END>\n",
            "-----------------------------------------------------------\n",
            "epoch 1 batch 100 loss 5.436881065368652\n",
            "English: be sensible\n",
            "Spanish Translation: sed razonables\n",
            "Spaniish Prediction: tom#tom#\n",
            "Evaluation translation of everyone is happy : <END>\n",
            "-----------------------------------------------------------\n",
            "epoch 1 batch 200 loss 5.2300028800964355\n",
            "English: she stood up\n",
            "Spanish Translation: ella se levant\n",
            "Spaniish Prediction: es#es#\n",
            "Evaluation translation of everyone is happy : <END>\n",
            "-----------------------------------------------------------\n",
            "epoch 1 batch 300 loss 5.408390998840332\n",
            "English: life is tough\n",
            "Spanish Translation: la vida es dura\n",
            "Spaniish Prediction: yo#a#a#\n",
            "Evaluation translation of everyone is happy : a#a#<END>\n",
            "-----------------------------------------------------------\n",
            "epoch 1 batch 400 loss 4.483172416687012\n",
            "English: it s tom s job\n",
            "Spanish Translation: es la tarea de tom\n",
            "Spaniish Prediction: no#es#\n",
            "Evaluation translation of everyone is happy : a#a#<END>\n",
            "-----------------------------------------------------------\n",
            "epoch 1 batch 500 loss 5.091350078582764\n",
            "English: i have an apple\n",
            "Spanish Translation: tengo una manzana\n",
            "Spaniish Prediction: no#es#a#\n",
            "Evaluation translation of everyone is happy : tom#<END>\n",
            "-----------------------------------------------------------\n",
            "epoch 1 batch 600 loss 4.741230487823486\n",
            "English: why are you sad\n",
            "Spanish Translation: por qu est s triste\n",
            "Spaniish Prediction: tom#es#a#a#\n",
            "Evaluation translation of everyone is happy : tom#<END>\n",
            "-----------------------------------------------------------\n",
            "epoch 1 batch 700 loss 5.771986484527588\n",
            "English: let me try again\n",
            "Spanish Translation: d jame tratar otra vez\n",
            "Spaniish Prediction: no#a#a#a#\n",
            "Evaluation translation of everyone is happy : a#a#<END>\n",
            "-----------------------------------------------------------\n",
            "epoch 1 batch 800 loss 5.507499694824219\n",
            "English: did you know that\n",
            "Spanish Translation: sab as eso\n",
            "Spaniish Prediction: tom#es#a#\n",
            "Evaluation translation of everyone is happy : tom#<END>\n",
            "-----------------------------------------------------------\n",
            "epoch 1 batch 900 loss 4.712717533111572\n",
            "English: thanks in advance\n",
            "Spanish Translation: gracias en avance\n",
            "Spaniish Prediction: no#es#\n",
            "Evaluation translation of everyone is happy : no#<END>\n",
            "-----------------------------------------------------------\n",
            "epoch 1 batch 1000 loss 4.984565258026123\n",
            "English: he changed his job\n",
            "Spanish Translation: l cambi de empleo\n",
            "Spaniish Prediction: no#es#es#\n",
            "Evaluation translation of everyone is happy : tom#<END>\n",
            "-----------------------------------------------------------\n",
            "epoch 1 batch 1100 loss 5.742531776428223\n",
            "English: stop that tickles\n",
            "Spanish Translation: para hace cosquillas\n",
            "Spaniish Prediction: no#es#a#a#a#\n",
            "Evaluation translation of everyone is happy : a#a#<END>\n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "transformer.train() # used to set the model in training mode\n",
        "# transformer.to(device)\n",
        "total_loss = 0\n",
        "num_epochs = 7\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  # print(f\"epoch {epoch}\")\n",
        "  iterator = iter(train_loader)\n",
        "  '''\n",
        "  looping on iterator we will get the batch of input_sequence and target_sequence\n",
        "  [(batch_of_input_sequence),(batch_of_target_sequence)]\n",
        "  '''\n",
        "\n",
        "  for batch_num,batch  in enumerate(iterator):\n",
        "    '''\n",
        "    batch_num{int}: current batch number\n",
        "    batch{list{tuple}}: batch of input_sequence and target_sequence\n",
        "    '''\n",
        "    transformer.train()\n",
        "    eng_batch,sp_batch = batch\n",
        "    # creating the mask for the eng_batch and sp_batch\n",
        "    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, sp_batch)\n",
        "    '''\n",
        "    ***important***\n",
        "    {the gradients of each mini-batch should be computed independantly}\n",
        "\n",
        "    .zero-grad():set gradient to zero at the start of training of each mini-batch\n",
        "                 so that while backpropogation the gradient is not accumulated:\n",
        "                              (means gradient of these mini batch would not effect the gradient of other mini-batch)\n",
        "\n",
        "    '''\n",
        "    optim.zero_grad()\n",
        "\n",
        "    sp_predictions = transformer(eng_batch,\n",
        "                                 sp_batch,\n",
        "                                 encoder_self_attention_mask,\n",
        "                                 decoder_self_attention_mask,\n",
        "                                 decoder_cross_attention_mask,\n",
        "                                 enc_start_token = False,\n",
        "                                 enc_end_token = False,\n",
        "                                 dec_start_token = True,\n",
        "                                 dec_end_token = True)\n",
        "    '''\n",
        "    labels{tensor}:\n",
        "          converting spanish sentences into their index values based on spanish_to_index\n",
        "    '''\n",
        "    # print(sp_batch)\n",
        "    labels = transformer.decoder.sentence_embedding.batch_tokenize(sp_batch, start_token=False, end_token=True)  # shspe (batch_size,max_sequence_length) {max_sequence_length  = num_queries}\n",
        "    # print(labels.shape)\n",
        "    '''\n",
        "    loss = criterian(....):\n",
        "        represent loss of each mini-batch\n",
        "        by computimg loss over all characters(or tokens) in a batch of sentences\n",
        "        loss[:max_sequnce_length] = loss of 1st sentence of batch\n",
        "    '''\n",
        "    loss = criterian(\n",
        "        sp_predictions.view(-1,sp_vocab_size), # shape (batch_size * num_queries,sp_vocab_size)\n",
        "        labels.view(-1) # shape (bach_size * num_queries.)\n",
        "    ) # shape (batch_size * num_queries)\n",
        "    # print(loss[:50])\n",
        "\n",
        "    '''\n",
        "    valid_indices:\n",
        "                setting true value where labels are not padding token\n",
        "                and false value where labels are padding token\n",
        "    '''\n",
        "    valid_indicies = torch.where(labels.view(-1) == sp_lng_to_index[PADDING_TOKEN], False, True) # shape (batch_size * num_queries)\n",
        "    # print(valid_indicies[:50])\n",
        "    # print(loss.sum())\n",
        "    # print(valid_indicies.sum())\n",
        "    '''\n",
        "    loss = loss.sum()/valid...:\n",
        "                represent a loss value(single number), where the loss of all padding tokens are ignored\n",
        "\n",
        "    '''\n",
        "    loss = loss.sum() / valid_indicies.sum()\n",
        "    # print(loss)\n",
        "\n",
        "    '''\n",
        "    loss.backward():\n",
        "                compute gradient or derivative using the loss function and model's parameters\n",
        "                *** Theory ***\n",
        "                          L = loss function\n",
        "                          w = model's weight or pparameter\n",
        "                          dL/dw = gradient of loss function wrt weight w\n",
        "                          dL/dw:\n",
        "                                represent how the loss function is changing if we change the model's parameter w(increase or decrease w value)\n",
        "\n",
        "                                computed using chain rule of calculus\n",
        "\n",
        "    optim.step():\n",
        "              updating the model parameter with above computed gradient or derivative\n",
        "              using a specific optmizer equation{Adam,Gradient descent,SGD,...}\n",
        "\n",
        "    .item():\n",
        "            return the value of torch tensor which containe only one value\n",
        "\n",
        "    '''\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "\n",
        "    if (batch_num % 100 == 0):\n",
        "      print(f\"epoch {epoch} batch {batch_num} loss {loss.item()}\")\n",
        "      print(f\"English: {eng_batch[0]}\")\n",
        "      print(f\"Spanish Translation: {sp_batch[0]}\")\n",
        "      '''\n",
        "      sp_predictions[0]:\n",
        "                  represent the output of transformer for a first trainable example in a batch\n",
        "      sp_sentence_predicted:\n",
        "                  represent the predicted index of spanish sentence for a first trainable example in a batch\n",
        "      '''\n",
        "\n",
        "      sp_sentence_predicted = torch.argmax(sp_predictions[0], # shape (num_queries,sp_vocab_size)\n",
        "                                           axis=1)  # shape (num_queries,)\n",
        "      # print(sp_sentence_predicted)\n",
        "      predicted_sentence = \"\"\n",
        "      for idx in sp_sentence_predicted:\n",
        "        # print(idx.item())\n",
        "        if idx == sp_lng_to_index[END_TOKEN]:\n",
        "          break\n",
        "        predicted_sentence += sp_index_to_lng[idx.item()]\n",
        "      print(f'Spaniish Prediction: {predicted_sentence}')\n",
        "\n",
        "\n",
        "      transformer.eval()  # used to set the model in evaluation mode\n",
        "      '''\n",
        "      ***Important***\n",
        "         a =  ('dksdkk')\n",
        "         type(a),len(a)\n",
        "         --> str, 6\n",
        "         a =  ('dksdkk',)\n",
        "         type(a),len(a)\n",
        "         ---> tuple, 1\n",
        "      '''\n",
        "      sp_sentence = (\"\",)\n",
        "      eng_sentence  = [\"everyone is happy.\"]\n",
        "      for i,sentence in enumerate(eng_sentence):\n",
        "        eng_sentence[i] = text_preprocessing(sentence)\n",
        "      eng_sentence = tuple(eng_sentence)\n",
        "      for word_counter in range(max_token_length):\n",
        "          encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, sp_sentence)\n",
        "          predictions = transformer(eng_sentence,\n",
        "                                          sp_sentence,\n",
        "                                          encoder_self_attention_mask,\n",
        "                                          decoder_self_attention_mask,\n",
        "                                          decoder_cross_attention_mask,\n",
        "                                          enc_start_token=False,\n",
        "                                          enc_end_token=False,\n",
        "                                          dec_start_token=True,\n",
        "                                          dec_end_token=False)\n",
        "          # print(predictions.shape)\n",
        "          '''\n",
        "          next_token_:\n",
        "                  contains raw prediction values for each token in vocabulary\n",
        "                  example:\n",
        "                        \"<start>i am happy<end>\"\n",
        "                        input token <start> feeded to transformer decoder\n",
        "                        then output of transformer represent raw prediction values,\n",
        "                        predicting what could be the next word (after <start> token) form the vocabulary\n",
        "                        shape (sp_vocab_size,)\n",
        "\n",
        "                                  I    <end>   a      m     h\n",
        "                        output = [21.5 , 7.9  , 0.1 , -20 , -2.4 ,...] {random_values}\n",
        "                        highest prediction value is the next word\n",
        "\n",
        "                        {real raw values range depnds on type activation function that is used}\n",
        "\n",
        "\n",
        "          '''\n",
        "          next_token_raw_distribution = predictions[0][word_counter] # shape (sp_vocab_size,)\n",
        "          # print(next_token_raw_distribution)\n",
        "          next_token_index = torch.argmax(next_token_raw_distribution).item()\n",
        "          # print(next_token_index)\n",
        "          next_token = sp_index_to_lng[next_token_index]\n",
        "          # print(next_token)\n",
        "          sp_sentence = (sp_sentence[0] + next_token,)\n",
        "          if (next_token == END_TOKEN):\n",
        "            break\n",
        "\n",
        "      print(f'Evaluation translation of {eng_sentence[0]} : {sp_sentence[0]}')\n",
        "      print(f'-----------------------------------------------------------')\n",
        "\n",
        "\n",
        "    # break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sp_index_to_lng),len(sp_lng_to_index)"
      ],
      "metadata": {
        "id": "U8Yo_Zga6VSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp_index_to_lng[3800]"
      ],
      "metadata": {
        "id": "68Rc1STz5ggI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaGJriaTNIRo"
      },
      "outputs": [],
      "source": [
        "transformer.eval()\n",
        "def translate(input_sentence):\n",
        "  '''\n",
        "      ***Important***\n",
        "         a =  ('dksdkk')\n",
        "         type(a),len(a)\n",
        "         --> str, 6\n",
        "         a =  ('dksdkk',)\n",
        "         type(a),len(a)\n",
        "         ---> tuple, 1\n",
        "      '''\n",
        "  sp_sentence = (\"\",)\n",
        "  eng_sentence  = [input_sentence]\n",
        "  for i,sentence in enumerate(eng_sentence):\n",
        "      eng_sentence[i] = text_preprocessing(sentence)\n",
        "  eng_sentence = tuple(eng_sentence)\n",
        "  for word_counter in range(max_token_length):\n",
        "      encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, sp_sentence)\n",
        "      predictions = transformer(eng_sentence,\n",
        "                                          sp_sentence,\n",
        "                                          encoder_self_attention_mask,\n",
        "                                          decoder_self_attention_mask,\n",
        "                                          decoder_cross_attention_mask,\n",
        "                                          enc_start_token=False,\n",
        "                                          enc_end_token=False,\n",
        "                                          dec_start_token=True,\n",
        "                                          dec_end_token=False)\n",
        "      # print(predictions.shape)\n",
        "      '''\n",
        "      next_token_:\n",
        "              contains raw prediction values for each token in vocabulary\n",
        "              example:\n",
        "                    \"<start>i am happy<end>\"\n",
        "                    input token <start> feeded to transformer decoder\n",
        "                    then output of transformer represent raw prediction values,\n",
        "                    predicting what could be the next word (after <start> token) form the vocabulary\n",
        "                    shape (sp_vocab_size,)\n",
        "\n",
        "                              I    <end>   a      m     h\n",
        "                    output = [21.5 , 7.9  , 0.1 , -20 , -2.4 ,...] {random_values}\n",
        "                    highest prediction value is the next word\n",
        "\n",
        "                    {real raw values range depnds on type activation function that is used}\n",
        "\n",
        "\n",
        "      '''\n",
        "      next_token_raw_distribution = predictions[0][word_counter] # shape (sp_vocab_size,)\n",
        "      # print(next_token_raw_distribution)\n",
        "      next_token_index = torch.argmax(next_token_raw_distribution).item()\n",
        "      # print(next_token_index)\n",
        "      next_token = sp_index_to_lng[next_token_index]\n",
        "      # print(next_token)\n",
        "      sp_sentence = (sp_sentence[0] + next_token,)\n",
        "      if (next_token == END_TOKEN):\n",
        "        break\n",
        "\n",
        "  print(f'Evaluation translation of  {eng_sentence[0]} : {sp_sentence[0]}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6Gm1FFlKLC6"
      },
      "outputs": [],
      "source": [
        "translate(\"i am happy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR4mHUlXLf2s"
      },
      "outputs": [],
      "source": [
        "translate('i am sad')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}